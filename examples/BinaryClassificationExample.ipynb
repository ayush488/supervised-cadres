{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're going to generate some synthetic binary classification data and show how to train supervised cadre models (SCM) on it. We'll train a model with the default parameters, and then we'll show how we can use cross-validation for hyperparameter tuning to get better performance.\n",
    "\n",
    "THIS NOTEBOOK IS INCOMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0, '../cadreModels')\n",
    "\n",
    "from classificationBinary import binaryCadreModel\n",
    "from sklearn.datasets import make_classification\n",
    "from scipy.stats import zscore, zmap\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data with the `sklearn.datasets.make_classification` function. Bind `X` and `y` into a `pd.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=50000, random_state=2125615, n_clusters_per_class=10, \n",
    "                           n_features=50, n_informative=25, n_repeated=15)\n",
    "\n",
    "data = pd.DataFrame(X)\n",
    "data.columns = ['f'+str(p) for p in data.columns]\n",
    "data = data.assign(target=y)\n",
    "features = data.columns[data.columns != 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the features are continuous, we should standardize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_tr, D_va = train_test_split(data, test_size=0.2, random_state=313616)\n",
    "\n",
    "D_va[features] = zmap(D_va[features], D_tr[features])\n",
    "D_tr[features] = zscore(D_tr[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `binaryCadreModel`'s initialization function takes the following arguments and default values:\n",
    "\n",
    "* `M=2` -- number of cadres in model\n",
    "* `gamma=10.` -- cadre-assignment sharpness\n",
    "* `lambda_d=0.01` -- regularization strength for cadre-assignment weight parameter `d`\n",
    "* `lambda_W=0.01` -- regularization strength for classification-weight parameter `W`\n",
    "* `alpha_d=0.9` -- elastic net mixing weight for cadre-assignment weight parameter `d`\n",
    "* `alpha_W=0.9` -- elastic net mixing with for classification-weight parameter `W`\n",
    "* `Tmax=10000` -- maximum number of SGD steps to take\n",
    "* `record=100` -- during training, how often goodness-of-fit metrics should be evaluated on the data\n",
    "* `eta=2e-3` -- initial stepsize / learning rate\n",
    "* `Nba=64` -- minibatch size\n",
    "* `eps=1e-3` -- convergence tolerance\n",
    "* `termination_metric='ROC_AUC'` -- training terminated if the difference between the most recent `termination_metric` value and the second most recent `termination_metric` is less than `eps`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you initialize a `binaryCadreModel`, you apply the `fit` method to train it. This method takes the following arguments and default values:\n",
    "\n",
    "* `data` -- `pd.DataFrame` of training data\n",
    "* `targetCol` -- string column-name of target feature in `data`\n",
    "* `cadreFts=None` -- `pd.Index` of column-names used for cadre-assignment\n",
    "* `predictFts=None` -- `pd.Index` of column-names used for target-prediction\n",
    "* `dataVa=None` -- optional `pd.DataFrame` of validation data \n",
    "* `seed=16162` -- seed for parameter initialization and minibatch generation\n",
    "* `store=False` -- whether or not copies `data` and `dataVa` should be added as attributes of the `binaryCadreModel`\n",
    "* `progress=False` -- whether or not goodness-of-fit metrics should be printed during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other attributes of the `binaryCadreModel` include:\n",
    "\n",
    "* `W` -- matrix of cadre-specific classification weights\n",
    "* `W0` -- vector of cadre-specific classification biases\n",
    "* `C` -- matrix of cadre centers\n",
    "* `d` -- vector of cadre-assignments weights\n",
    "* `metrics` -- a `dict` with `'training'` and `'validation'` as keys. Each item is a `pd.DataFrame` of goodness-of-fit metrics evaluated during training. Metrics include loss, accuracy, ROC AUC, and precision-recall (PR) AUC\n",
    "* `time` -- list of computer-time values it took for each SGD step to be evaluated\n",
    "* `proportions` -- during training, the proportion of the training data assigned to each cadre is recorded. This is a `pd.DataFrame` of those proportions, which lets you see if cadre assignments have converged to a stable distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scm = binaryCadreModel(Tmax=17001, record=50, eps=1e-4, lambda_W=1e-3, lambda_d=1e-3, M=10)\n",
    "scm.fit(D_tr, 'target', features, features, D_va, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scm.metrics['validation'].drop('loss', axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scm.metrics['training']['loss'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scm.scoreMetrics(D_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scm.entropy(D_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, l, G, m, l = scm.predictFull(D_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(m).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scmCrossval(d_tr, d_va, d_te, M, l_W, l_d, cadre_fts, predict_fts, Tmax, record):\n",
    "    mod = binaryCadreModel(\n",
    "                Tmax=Tmax, record=record,\n",
    "                M=M, alpha_d=0.99, alpha_W=0.99, lambda_d=l_d, lambda_W=l_W, gamma=1.)\n",
    "        \n",
    "    mod.fit(d_tr, 'target', cadre_fts, predict_fts, d_va, progress=False)\n",
    "    \n",
    "    ## evaluate on validation and test sets\n",
    "    err_va = mod.scoreMetrics(d_va)\n",
    "    err_te = mod.scoreMetrics(d_te)\n",
    "    \n",
    "    ## return everything as a list\n",
    "    return mod, err_va, err_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_ds = np.array([0.01, 0.001])\n",
    "l_Ws = np.array([0.01, 0.001])\n",
    "Ms = np.array([4,6,8,10])\n",
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=n_folds, random_state=1414)\n",
    "\n",
    "n_jobs = np.minimum(12, n_folds * Ms.shape[0] * l_ds.shape[0] * l_Ws.shape[0])\n",
    "\n",
    "results = (Parallel(n_jobs=n_jobs, backend='threading', verbose=11)(delayed(scmCrossval)\n",
    "                    (D_tr.iloc[tr], D_tr.iloc[va], D_va, M, l_W, l_d, features, features, 20001, 1000) \n",
    "                    for (M, l_d, l_W, (fold, (tr, va))) in product(Ms, l_ds, l_Ws, enumerate(kf.split(D_tr)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scores(results):\n",
    "    results_va, results_te = [], []\n",
    "    for model, scores_va, scores_te in results:\n",
    "        results_va.append(scores_va)\n",
    "        results_va[-1] = results_va[-1].assign(M=model.M, lambda_d=model.lambda_d, lambda_W=model.lambda_W)\n",
    "        \n",
    "        results_te.append(scores_te)\n",
    "        results_te[-1] = results_te[-1].assign(M=model.M, lambda_d=model.lambda_d, lambda_W=model.lambda_W)\n",
    "    results_va = pd.concat(results_va).reset_index(drop=True)\n",
    "    results_te = pd.concat(results_te).reset_index(drop=True)\n",
    "    print(results_va.head())\n",
    "    print(results_te.head())\n",
    "    return results_va, results_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_scores = extract_scores(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_root]",
   "language": "python",
   "name": "conda-env-my_root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
