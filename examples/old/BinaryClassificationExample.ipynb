{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're going to generate some synthetic binary classification data and show how to train supervised cadre models (SCM) on it. We'll train a model with the default parameters, and then we'll show how we can use cross-validation for hyperparameter tuning to get better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0, '../cadreModels')\n",
    "\n",
    "from classificationBinary import binaryCadreModel\n",
    "from sklearn.datasets import make_classification\n",
    "from scipy.stats import zscore, zmap\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data with the `sklearn.datasets.make_classification` function. Bind `X` and `y` into a `pd.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=50000, random_state=2125615, n_clusters_per_class=10, \n",
    "                           n_features=50, n_informative=25, n_repeated=15)\n",
    "\n",
    "data = pd.DataFrame(X)\n",
    "data.columns = ['f'+str(p) for p in data.columns]\n",
    "data = data.assign(target=y)\n",
    "features = data.columns[data.columns != 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f41</th>\n",
       "      <th>f42</th>\n",
       "      <th>f43</th>\n",
       "      <th>f44</th>\n",
       "      <th>f45</th>\n",
       "      <th>f46</th>\n",
       "      <th>f47</th>\n",
       "      <th>f48</th>\n",
       "      <th>f49</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.562447</td>\n",
       "      <td>-4.496746</td>\n",
       "      <td>-4.496746</td>\n",
       "      <td>0.523007</td>\n",
       "      <td>5.937111</td>\n",
       "      <td>0.628727</td>\n",
       "      <td>0.261670</td>\n",
       "      <td>-3.003903</td>\n",
       "      <td>0.523007</td>\n",
       "      <td>2.877445</td>\n",
       "      <td>...</td>\n",
       "      <td>2.169409</td>\n",
       "      <td>4.228746</td>\n",
       "      <td>-2.491846</td>\n",
       "      <td>0.389091</td>\n",
       "      <td>-1.462236</td>\n",
       "      <td>-1.188389</td>\n",
       "      <td>0.389091</td>\n",
       "      <td>5.371964</td>\n",
       "      <td>0.523007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.466490</td>\n",
       "      <td>1.704545</td>\n",
       "      <td>1.704545</td>\n",
       "      <td>1.158476</td>\n",
       "      <td>-0.013365</td>\n",
       "      <td>0.751370</td>\n",
       "      <td>-2.209397</td>\n",
       "      <td>2.166053</td>\n",
       "      <td>1.158476</td>\n",
       "      <td>0.362309</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.412764</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>-4.074863</td>\n",
       "      <td>3.412430</td>\n",
       "      <td>-1.229256</td>\n",
       "      <td>-3.037757</td>\n",
       "      <td>3.412430</td>\n",
       "      <td>-5.643174</td>\n",
       "      <td>1.158476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.950077</td>\n",
       "      <td>3.122326</td>\n",
       "      <td>3.122326</td>\n",
       "      <td>-0.534232</td>\n",
       "      <td>-3.825865</td>\n",
       "      <td>-1.757176</td>\n",
       "      <td>1.554950</td>\n",
       "      <td>0.632377</td>\n",
       "      <td>-0.534232</td>\n",
       "      <td>3.675752</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.114574</td>\n",
       "      <td>0.188603</td>\n",
       "      <td>2.145846</td>\n",
       "      <td>3.929885</td>\n",
       "      <td>-7.317242</td>\n",
       "      <td>-4.200953</td>\n",
       "      <td>3.929885</td>\n",
       "      <td>-4.407239</td>\n",
       "      <td>-0.534232</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.896450</td>\n",
       "      <td>1.962297</td>\n",
       "      <td>1.962297</td>\n",
       "      <td>5.707130</td>\n",
       "      <td>-3.910068</td>\n",
       "      <td>1.387582</td>\n",
       "      <td>3.167782</td>\n",
       "      <td>5.575011</td>\n",
       "      <td>5.707130</td>\n",
       "      <td>-0.543254</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480521</td>\n",
       "      <td>4.057712</td>\n",
       "      <td>0.410260</td>\n",
       "      <td>2.630305</td>\n",
       "      <td>7.187664</td>\n",
       "      <td>3.307076</td>\n",
       "      <td>2.630305</td>\n",
       "      <td>2.483412</td>\n",
       "      <td>5.707130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.032346</td>\n",
       "      <td>2.897824</td>\n",
       "      <td>2.897824</td>\n",
       "      <td>-0.938040</td>\n",
       "      <td>1.600827</td>\n",
       "      <td>1.681539</td>\n",
       "      <td>2.033267</td>\n",
       "      <td>-1.647245</td>\n",
       "      <td>-0.938040</td>\n",
       "      <td>0.065656</td>\n",
       "      <td>...</td>\n",
       "      <td>2.976090</td>\n",
       "      <td>6.443671</td>\n",
       "      <td>1.234381</td>\n",
       "      <td>1.099088</td>\n",
       "      <td>7.176274</td>\n",
       "      <td>-2.604756</td>\n",
       "      <td>1.099088</td>\n",
       "      <td>-1.910424</td>\n",
       "      <td>-0.938040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0 -0.562447 -4.496746 -4.496746  0.523007  5.937111  0.628727  0.261670   \n",
       "1 -0.466490  1.704545  1.704545  1.158476 -0.013365  0.751370 -2.209397   \n",
       "2  0.950077  3.122326  3.122326 -0.534232 -3.825865 -1.757176  1.554950   \n",
       "3  0.896450  1.962297  1.962297  5.707130 -3.910068  1.387582  3.167782   \n",
       "4 -0.032346  2.897824  2.897824 -0.938040  1.600827  1.681539  2.033267   \n",
       "\n",
       "         f7        f8        f9   ...         f41       f42       f43  \\\n",
       "0 -3.003903  0.523007  2.877445   ...    2.169409  4.228746 -2.491846   \n",
       "1  2.166053  1.158476  0.362309   ...   -1.412764  0.007301 -4.074863   \n",
       "2  0.632377 -0.534232  3.675752   ...   -1.114574  0.188603  2.145846   \n",
       "3  5.575011  5.707130 -0.543254   ...    1.480521  4.057712  0.410260   \n",
       "4 -1.647245 -0.938040  0.065656   ...    2.976090  6.443671  1.234381   \n",
       "\n",
       "        f44       f45       f46       f47       f48       f49  target  \n",
       "0  0.389091 -1.462236 -1.188389  0.389091  5.371964  0.523007       1  \n",
       "1  3.412430 -1.229256 -3.037757  3.412430 -5.643174  1.158476       1  \n",
       "2  3.929885 -7.317242 -4.200953  3.929885 -4.407239 -0.534232       0  \n",
       "3  2.630305  7.187664  3.307076  2.630305  2.483412  5.707130       0  \n",
       "4  1.099088  7.176274 -2.604756  1.099088 -1.910424 -0.938040       1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the features are continuous, we should standardize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/newa/.conda/envs/my_root/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/newa/.conda/envs/my_root/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/newa/.conda/envs/my_root/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "D_tr, D_va = train_test_split(data, test_size=0.2, random_state=313616)\n",
    "\n",
    "D_va[features] = zmap(D_va[features], D_tr[features])\n",
    "D_tr[features] = zscore(D_tr[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `binaryCadreModel`'s initialization function takes the following arguments and default values:\n",
    "\n",
    "* `M=2` -- number of cadres in model\n",
    "* `gamma=10.` -- cadre-assignment sharpness\n",
    "* `lambda_d=0.01` -- regularization strength for cadre-assignment weight parameter `d`\n",
    "* `lambda_W=0.01` -- regularization strength for classification-weight parameter `W`\n",
    "* `alpha_d=0.9` -- elastic net mixing weight for cadre-assignment weight parameter `d`\n",
    "* `alpha_W=0.9` -- elastic net mixing with for classification-weight parameter `W`\n",
    "* `Tmax=10000` -- maximum number of SGD steps to take\n",
    "* `record=100` -- during training, how often goodness-of-fit metrics should be evaluated on the data\n",
    "* `eta=2e-3` -- initial stepsize / learning rate\n",
    "* `Nba=64` -- minibatch size\n",
    "* `eps=1e-3` -- convergence tolerance\n",
    "* `termination_metric='ROC_AUC'` -- training terminated if the difference between the most recent `termination_metric` value and the second most recent `termination_metric` is less than `eps`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you initialize a `binaryCadreModel`, you apply the `fit` method to train it. This method takes the following arguments and default values:\n",
    "\n",
    "* `data` -- `pd.DataFrame` of training data\n",
    "* `targetCol` -- string column-name of target feature in `data`\n",
    "* `cadreFts=None` -- `pd.Index` of column-names used for cadre-assignment\n",
    "* `predictFts=None` -- `pd.Index` of column-names used for target-prediction\n",
    "* `dataVa=None` -- optional `pd.DataFrame` of validation data \n",
    "* `seed=16162` -- seed for parameter initialization and minibatch generation\n",
    "* `store=False` -- whether or not copies `data` and `dataVa` should be added as attributes of the `binaryCadreModel`\n",
    "* `progress=False` -- whether or not goodness-of-fit metrics should be printed during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other attributes of the `binaryCadreModel` include:\n",
    "\n",
    "* `W` -- matrix of cadre-specific classification weights\n",
    "* `W0` -- vector of cadre-specific classification biases\n",
    "* `C` -- matrix of cadre centers\n",
    "* `d` -- vector of cadre-assignments weights\n",
    "* `metrics` -- a `dict` with `'training'` and `'validation'` as keys. Each item is a `pd.DataFrame` of goodness-of-fit metrics evaluated during training. Metrics include loss, accuracy, ROC AUC, and precision-recall (PR) AUC\n",
    "* `time` -- list of computer-time values it took for each SGD step to be evaluated\n",
    "* `proportions` -- during training, the proportion of the training data assigned to each cadre is recorded. This is a `pd.DataFrame` of those proportions, which lets you see if cadre assignments have converged to a stable distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we're going to train an SCM without really tuning the hyperparameters. Note that `Tmax` is quite large (20001). The number of SGD steps needed for training tends to vary wildly by dataset. Sometimes, only a few hundred are needed. Because of the convergence tolerance `eps`, if you specify too large a `Tmax`, the training will stop after progress slows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers being printed: SGD iteration, training loss, training accuracy, validation loss, validation accuracy, time\n",
      "0\n",
      "50 1.2984807 0.517075 1.297145 0.5141 0.16040802001953125\n",
      "100 1.1886443 0.550775 1.1874509 0.5463 11.967761516571045\n",
      "150 1.1525713 0.565475 1.151257 0.5635 22.949254035949707\n",
      "200 1.1297761 0.574425 1.128429 0.5765 33.663105726242065\n",
      "250 1.1135666 0.58145 1.1121567 0.5834 43.84789514541626\n",
      "300 1.1009313 0.587875 1.099615 0.5928 53.823208808898926\n",
      "350 1.0902662 0.593575 1.0889814 0.5989 63.28908324241638\n",
      "400 1.0815023 0.598125 1.0802588 0.6023 73.21573829650879\n",
      "450 1.0744634 0.602525 1.073235 0.6045 82.95269703865051\n",
      "500 1.0682241 0.606975 1.0670334 0.6081 92.10580277442932\n",
      "550 1.0628145 0.6104 1.0616798 0.6132 101.66183662414551\n",
      "600 1.0579996 0.6147 1.0569385 0.6179 111.35325717926025\n",
      "650 1.0539076 0.6175 1.0528872 0.6196 121.34262418746948\n",
      "700 1.050068 0.6201 1.0491099 0.6229 131.49778866767883\n",
      "750 1.0468949 0.6219 1.0459743 0.6246 140.51393866539001\n",
      "800 1.0438342 0.624325 1.042928 0.6255 150.43138599395752\n",
      "850 1.0410184 0.6263 1.0401587 0.6274 159.74762153625488\n",
      "900 1.0385079 0.62785 1.0377221 0.6302 169.33587527275085\n",
      "950 1.0362376 0.63 1.0354745 0.6319 178.9903061389923\n",
      "1000 1.0341733 0.6319 1.0333968 0.6332 189.06610560417175\n",
      "1050 1.0324463 0.633375 1.0317111 0.6335 199.0310995578766\n",
      "1100 1.0306022 0.634475 1.029889 0.6357 209.14070653915405\n",
      "1150 1.0289488 0.636575 1.028254 0.6367 219.67273902893066\n",
      "1200 1.0274383 0.638225 1.0267512 0.6391 230.64619517326355\n",
      "1250 1.026089 0.639075 1.0254306 0.6398 241.1908106803894\n",
      "1300 1.0246923 0.6407 1.0240526 0.6419 251.37676692008972\n",
      "1350 1.0235015 0.641525 1.0228912 0.6421 261.7817792892456\n",
      "1400 1.0224794 0.64255 1.0218996 0.6434 271.5611367225647\n",
      "1450 1.0213741 0.6434 1.020763 0.6454 281.3336479663849\n",
      "1500 1.0202988 0.64465 1.0196947 0.6457 291.50555992126465\n",
      "1550 1.0193259 0.64545 1.0187743 0.6454 301.8103790283203\n",
      "1600 1.0184225 0.6461 1.0178884 0.646 311.5369575023651\n",
      "1650 1.01746 0.64725 1.0169306 0.6459 321.4680836200714\n",
      "1700 1.016701 0.648575 1.0161842 0.646 330.8765652179718\n",
      "1750 1.0160935 0.64905 1.0155878 0.6472 340.7576570510864\n",
      "1800 1.0153413 0.649925 1.0148764 0.6468 350.72644329071045\n",
      "1850 1.0146592 0.650875 1.0142295 0.6472 360.47241163253784\n",
      "1900 1.0140145 0.65225 1.0136396 0.6481 370.663964509964\n",
      "1950 1.0133808 0.6531 1.0130249 0.6493 380.45010590553284\n",
      "2000 1.0128322 0.654 1.0125104 0.6505 390.78141808509827\n",
      "2050 1.0123044 0.655025 1.0119956 0.652 401.918123960495\n",
      "2100 1.0117325 0.655475 1.0114225 0.6536 411.69665694236755\n",
      "2150 1.0112698 0.65605 1.0109704 0.6547 421.62110018730164\n",
      "2200 1.010825 0.656625 1.0105476 0.6544 431.1120300292969\n",
      "2250 1.0104668 0.657125 1.0102031 0.6555 440.68647050857544\n",
      "2300 1.0100971 0.657725 1.0098437 0.6558 450.675719499588\n",
      "2350 1.0097644 0.6576 1.0095159 0.6558 460.3006613254547\n",
      "2400 1.0094018 0.6576 1.0091656 0.6567 470.0137550830841\n",
      "2450 1.0090091 0.65835 1.0087845 0.6576 480.0735487937927\n",
      "2500 1.008688 0.658375 1.0084815 0.6583 490.6084771156311\n",
      "2550 1.0084109 0.659175 1.0082192 0.659 500.2664301395416\n",
      "2600 1.0081751 0.6601 1.0080003 0.6595 510.2110471725464\n",
      "2650 1.0079514 0.66075 1.0077859 0.6609 519.0919890403748\n",
      "2700 1.0077227 0.661925 1.0075693 0.6616 527.9099519252777\n",
      "2750 1.0074484 0.662225 1.0073074 0.6624 537.3427712917328\n",
      "2800 1.0071951 0.6634 1.0070647 0.6629 546.765200138092\n",
      "2850 1.0069638 0.663575 1.0068378 0.664 555.5264751911163\n",
      "2900 1.0066494 0.664225 1.0065564 0.6632 564.8310313224792\n",
      "2950 1.006421 0.6652 1.006345 0.6635 574.4652636051178\n",
      "3000 1.0062405 0.66555 1.0061991 0.6641 583.8569414615631\n",
      "3050 1.0059494 0.66635 1.005922 0.6646 593.2611258029938\n",
      "3100 1.0057079 0.66655 1.0057105 0.6657 602.7320125102997\n",
      "3150 1.005502 0.666825 1.0055379 0.6658 612.2166702747345\n",
      "3200 1.005301 0.667125 1.0053685 0.6662 621.5780584812164\n",
      "3250 1.0051064 0.667875 1.005192 0.6665 631.9755754470825\n",
      "3300 1.0049787 0.6683 1.0050905 0.6675 641.428147315979\n",
      "3350 1.0047683 0.66945 1.0048943 0.6686 651.4228754043579\n",
      "3400 1.004645 0.6696 1.0047716 0.6687 661.7682123184204\n",
      "3450 1.0044938 0.6697 1.0046428 0.6685 671.3290729522705\n",
      "3500 1.004345 0.66995 1.0045022 0.6697 679.9789485931396\n",
      "3550 1.0042195 0.67065 1.0043861 0.6698 688.838677406311\n",
      "3600 1.0040691 0.670625 1.0042535 0.671 698.3323218822479\n",
      "3650 1.0039271 0.67085 1.0041189 0.6711 707.7633645534515\n",
      "3700 1.0037835 0.671025 1.003992 0.6708 717.1686017513275\n",
      "3750 1.0037214 0.671125 1.0039344 0.6709 727.0570106506348\n",
      "3800 1.0036013 0.671825 1.0038103 0.6719 736.6477103233337\n",
      "3850 1.0034882 0.67215 1.003703 0.6714 746.4842140674591\n",
      "3900 1.0032843 0.6723 1.0034928 0.6719 755.7556331157684\n",
      "3950 1.0031608 0.672675 1.003372 0.6722 765.3188097476959\n",
      "4000 1.0030643 0.67285 1.0032868 0.6719 775.0872633457184\n",
      "4050 1.0029649 0.67365 1.0031915 0.6721 784.9987847805023\n",
      "4100 1.0028217 0.673975 1.0030594 0.6722 794.3359611034393\n",
      "4150 1.0027512 0.674475 1.0029904 0.6717 803.9905259609222\n",
      "4200 1.002605 0.675175 1.0028439 0.6735 813.9735233783722\n",
      "4250 1.002497 0.67545 1.0027444 0.6747 823.2619225978851\n",
      "4300 1.0023721 0.6758 1.002629 0.6741 832.4009275436401\n",
      "4350 1.0023291 0.676375 1.0025992 0.6745 842.8124632835388\n",
      "4400 1.0022455 0.676675 1.002525 0.6745 851.8851416110992\n",
      "4450 1.0021421 0.677225 1.0024272 0.6745 861.1342124938965\n",
      "4500 1.0020936 0.6774 1.0023941 0.6747 870.4169545173645\n",
      "4550 1.0020189 0.67765 1.0023285 0.6742 879.427497625351\n",
      "4600 1.0019748 0.67765 1.0022922 0.6746 888.7499928474426\n",
      "4650 1.0018576 0.678125 1.0021815 0.6749 898.3625662326813\n",
      "4700 1.0017458 0.6782 1.0020739 0.6759 907.7317795753479\n",
      "4750 1.0016718 0.67865 1.0020099 0.6756 916.5043303966522\n",
      "4800 1.0016237 0.6792 1.0019569 0.6751 925.3210892677307\n",
      "4850 1.0015059 0.68025 1.0018393 0.6752 934.3281033039093\n",
      "4900 1.0014584 0.680175 1.0018041 0.6757 943.5932660102844\n",
      "4950 1.0013764 0.680375 1.0017209 0.6762 952.934769153595\n",
      "5000 1.0013605 0.6803 1.0017065 0.677 962.6235640048981\n",
      "5050 1.0012981 0.680525 1.0016475 0.6762 971.6014995574951\n",
      "5100 1.0012498 0.6807 1.0016023 0.6766 980.6819007396698\n",
      "5150 1.0012249 0.6811 1.0015798 0.6767 989.9250795841217\n",
      "5200 1.001187 0.6813 1.0015426 0.6769 999.1021206378937\n",
      "training has terminated because: lack of sufficient decrease in validation ROC_AUC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<classificationBinary.binaryCadreModel at 0x7f867f5478d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scm = binaryCadreModel(Tmax=20001, record=50, eps=1e-4, lambda_W=1e-3, lambda_d=1e-3, M=10, gamma=1.)\n",
    "scm.fit(D_tr, 'target', features, features, D_va, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've trained a model, we can plot the trajectories of the ROC AUC, PR AUC, and accuracy. These plots suggest that a little bit more training time might have been useful, as the AUCs are still increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f867e933b70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl8VNX9//HX7DPZ98lKAoRAIKwqooJUVgWXFnBpbUu/LdLWpbXar1ptsfVX7aat9Kvfql+rVmy11qUuUFEWBURARAkQ1pCQhWSSzEwmyUxmu/f+/ghGYwJByD6f5+Pho+TOufeeM+i7J+eee45O0zQNIYQQEUHf3xUQQgjRdyT0hRAigkjoCyFEBJHQF0KICCKhL4QQEURCXwghIoiEvhBCRBAJfSGEiCAS+kIIEUGM/V2BL1JVFUU585eEDQbdWZ0/WERKOyFy2hop7YTIaWtfttNkMpxWuQEX+oqi0djoO+PzExKizur8wSJS2gmR09ZIaSdETlv7sp2pqbGnVU6Gd4QQIoJI6AshRAQ5reGdTZs2cf/996OqKldffTXLly/v8PkDDzzA9u3bAfD7/TidTnbu3AlAYWEhBQUFAGRkZPDYY4/1ZP2FEEJ8Cd2GvqIo3HfffTz99NPY7XaWLFnCrFmzyM/Pby9z9913t/951apVlJSUtP9stVp57bXXerjaQgghzkS3wzvFxcXk5uaSk5OD2Wxm4cKFrF+//qTlV69ezeWXX96jlRRCCNEzuu3pOxwO0tPT23+22+0UFxd3Wba6upqqqiqmTZvWfiwQCLBo0SKMRiPLly9nzpw5p7yfwaAjISHqdOvfxfn6szp/sIiUdkLktDVS2gmR09aB2M5uQ7+rjbV0Ol2XZVevXs38+fMxGD6bL7px40bsdjuVlZUsXbqUgoIChg0bdtL7yZTN0xMp7YTIaWuktBMip60Dccpmt6Gfnp5ObW1t+88Oh4O0tLQuy65Zs4YVK1Z0OGa32wHIyclh6tSplJSUnDL0hRBiqAqEVWqb/DiaAzR4gzi9QbxBBYNOh04HFwxPYlz66YX3meo29MePH095eTmVlZXY7XZWr17NQw891Knc0aNHaWpqYvLkye3HPB4PNpsNs9mMy+Vi165dLFu2rGdbIIQQA0hIUTnS4KWktpnKpiBVTi/13iB1J4L+VNy+UP+HvtFoZMWKFSxbtgxFUVi8eDGjRo1i5cqVFBUVMXv2bKBtaGfBggUdhn5KS0u599570el0aJrGDTfc0GHWjxBCDBYhRaXC3UpdS4D65iAN3iDNgTDeYJhmf5gGb5C6lrZwD6ttw+KxViNpMWZSYyzkp0SREWclM96KPcZIuqmVFH0LUQQAUNGhJmb2ejt0WleD9v0oFFJkTP80REo7IXLaGinthIHZ1iZ/CEdzgPqWIA0tbaHe4A1S3xLgmKuVCrePLy6jYzHqiTYbiLUYSTkR7ukxRs6JaaTIVEmOvo5gYx16vxtdqxO914HB60Dnd6LT1E518I+6iuZ5j55R/XtsTF8IIYaCsKJyvClAVWNr27h6S5D65rafj7lbcflCnc6JtRhJiTYzPMHE4mFQaHGSoXOTqLqIVdwYQ83oQl50wWZ0AQ/6+kb0FQ3olED7NQxGK6o1EdWahBptJ5w2ATUqFdWWjGZNQjOdmN2jaYTskzvVoadJ6AshhgxN06hrCVJS28x+RzPHXK3Ut7T13utbAh166nodJEebyY9RuDariQJrI1nGJpLwEK82Eh1yYmqtR+91oK+tRnc83OFeqiUezRyHZo5GM8WgxmSgJBei2pIJJxWgJBcSkzeeRl/Xsx37i4S+EGLQCSkqtU0BKtytHHP7OOZq5ajTS5nTh8ffFs5Gncr4hBD5Nj+zU7wMy/CQp68nXXUQF3RgCdRj8Naib2yGxo7XV00xqNFpqFFphOyTUEZdiRI/HCU+DzUmEzU6FQyW7itqjgLfwBrGktAXQgw4YVWjtsnfNpb+6XBMc4DapgC1zQGcJ2bB6FFJxsMoq4eLYjx8L8XNSH0t2aEyYppL0bf6oLXjtZVoO2pMFmrSKELZ09tCPDYbJTYLNTod1ZYERms/tLpvSOgLIfpFWNWo8fipawnQ0BKkriVAqdPHkXovR50t2JQWMnQuMnQuMg0eplmaGWbykG71kGJxEa84iQo60Wsnhl1a2v5pG14ZjT/nOpT44Wi2ZFRbMmpUGkpcNhht/dru/iahL4ToFYGwSv2JQHf6gjiaAxz3+Dne2EpTkxMaK7Br9aTomkikmRSdh6uNTkYYG7BbHFjUL3TRw6Aa4lFt6ahRaajRY2mNyWjrncdkoMTloMZmo5l7d577YCehL4Q4Y6qmUeFu5WiDl2qPn5pGHx53HQF3FQZfHck6Dyk0kaLzUKBrYL6+jhxdHdG0gukL1zLFoMZmocQVoMTNpiU2CzU6AyUmvS3Yo1KH9LBLX5HQF0KcNqc3yP7jLhzHSgjUlmBrPMhItZzJujpm65pJpBmD7sQUGfNn5ynGKJToDLSEfNS4S1DsI2kx2lFjs9p67dZECfQ+IqEvhOhAVUI01FXjrC2nuaGKUGMlhqYqov3HyVJrWKirwaxTAFB0BjxxeajxYzHHpuCPSUWNSmnrmZ/onau2FDB1HEdPSIgiOMBezooUEvpCRCIliMFzjFD9IdxVJSh1B7A1lxEXridFbcSu6/jqaStW3OZ0WqPyqEq9lLjscRhSCwknjWqfuhjo6j5iwJHQF2Ko0jT0PgcG1yH0zkO01h1BcR3F0lxBQvA4BtqWAbADx7Ukqg05VNnOQ4lOxxCfSUxyNkn2PKKTc8CWhEmnax+G14Dwye4rBjQJfSEGO03F4CnH0FCCsaEEXKVo7jLMzRWYlZb2YjrNRrlmp1LLwmm9gEDcCEyp+aQOG8fonAzyrKZT3EQMFRL6QgwGmobO78LQVIm+uQpDUwUGdykG5wEMrkMYlLbpjWH0VKhpVGh2jmkXUE4WrfGjiMoYQ1bmMEbbY5mUHIXJ0O1OqWKIktAXYiAJejE17MHQsB9D41GMnjL0TRXom6vRKx1HzV3Es1/N5qA6kwNaDpWmfGKzx5GfnkROgo2RiTbmJEVhNkrAi89I6AvRlzQNvbcGfVMVhuZKDM3VbQt6eWsxtlSQ0nCwfcldv85GhS6DI+FUKtRCjmvJVGsp1BnsGBJySU1OJifBRk6ijcX2GIYnRZ10K1MhPiWhL0Qv0gVbMNYXY3R8jKl2F6baj9C3NnQoEzTF4zWncMyQxmbdErYEctmr5hG2pjI6LZYRKVHkJto4PzGKYYk2UmPMEu7ijEnoC9ETNA19Sw3Ghr0YnQcwuA6e+N9D6Gib/hiOH05V0gV8ooxkd2syH3piOehPIOBve4vJYtQzdVgCF49M5ra8ROyxFgl30eMk9IX4slQFg/swxoZ9GBtKMDr3Y6zfi97vai+ixOYQThpNXdZ8PlZGsMadxYYqhVaHisWoJz8lmlGjopmXEk12oo3seCtjhiXR2uLvx4aJSCChL0Q3dL56TLU7MdXsxOj4BFP9HnThtrdJNb2ZcFIBgeFz8SeN45B+ODt8GXxSr7Knuom6g21LAKfF6Fgw1s6Mkcmcm5OApYuHqxaj/ourAAvR4yT0hfg8JYShsRST42NMNR9irNmB0VMOnAj41HG0Fl5LOG0i1dYCdnqTKK71s6e6icOftJzYmamOzDgLE7PimZIdz3nDEhiWaJOhGjEgSOiLyKUqGNyHMNXuwuj4GGP9Hoyuw+jUtt65ak0ilHEe/rHXUxk9ng/8ORx0hiit9XJkr4/G1kagEZtJz7j0WL49NYeijDiKMmJJijKf+t5C9BMJfRE5lCBG535MNR9iqv4A0/Ft6AMeAFRLAmH7RFpzLiaUXEiFZRSbXEl8WNnIxx94TmzBd4wok4ERKVFcPDKJQnss4zPjGJkSjVEvvXgxOEjoi6FJDWNwH8FYvxdj/R5Mdbsx1u9Bd+IFJyUul8CIywhlTSNkn8LhUBo7Kz18Ut3E7j0e6lvcgJvMOAsXj0xmUlY8E7LiyJVhGjHISeiLQU/ffByjcz8G1yGMroMYnAcwug+3B7xmtBFOGUdr0VLC9smE0s/BZ7XzUZWHLaVO3t9UT01TFQBpMWamZLeNxU/NTSQ7IbK31hNDj4S+GHR0vgZMx7dhrtyMuWozhqaK9s+UKDtKyhhac6YTTi4knDoBJWEEfgUO1rVQfLyJj/a42Fl5lEBYxWrUMzU3ke+cP4wL8hLJiJONPMTQJqEvBr4WB5bDGzBVbcVUsx2j+wjQtr1eKOtCfBOXEU4pQkkqQLMmAKCoGqUNXrYedrG1fC/Fx5tQ1LaXpIYl2vjq+HSmj0hicnbX0yeFGKok9MWAovM1YKr9CKOzpO2NVud+jI1HMQGqObZtNs2Yawhlnk84dQKa3khVo5+jTi9llU2Uu2opbfBR5vIRCLetYVOQGs3152QxITOe8Zkys0ZENgl90X+UYNsbrXWfYHJ8jLH2o8/mxKNDjRtGOHkMuinfpinpXMKpRaA3omkaB+ta2PBBFesPNVDh/uyVptQYMyOTo1k8MYPRaTFMHZZASoylnxooxMAjoS/6jC7Q1DZVsmZHW2/+c7NpVFsqofQp+MdeTyj9nLaAN0UBbfup+p0tfFTh4b1SJ5tKnTiaAxh0cE5OAtdNyaLQHkNeUhQxFvlXWohTkf9CRO9RFYx1n2A+tgFz5WaMdZ+g09S2N1vTxtNatJRQ+hTC9smoMZnwhamQvqDCR5WNbK0o5Z0SBx5/GItRz7TcRJZfkMvFI5NJiJLdnoT4MiT0RY/S+eoxV7yHuWIj5spN6P1uNJ2ecNpEfOfcQih7OqH0Ke2baX+eqmnsr23m/TIXO441sre2GUXViLEYmTEiiVmjUpiWl4jVZOiHlgkxNEjoi7OjhDDV7MBcuQlT5SZM9XsAUG0pBHNntf2TczGaNbHL053eIDsq3Gwvd/NBuRuXL4ReB4X2WL51bjbn5iTwlaIMWX1SiB4ioS++vLAfc+UmLKVrMJe/gz7gQdMbCaWfg/f8OwjmXkI4ZRzoup4KWeluZf2hejYcbmC/o23j7nirkfNzE5k+MokL8pJIsH02bCOrTwrRc04r9Ddt2sT999+PqqpcffXVLF++vMPnDzzwANu3bwfA7/fjdDrZuXMnAK+++ip/+ctfAPjhD3/I1772tZ6sv+grahhT9TYsh1/FUvof9MEmVEs8wby5BEZcSih7Opo5pstTP51t894RJ++VOjlc7wVgXHosN07P4/zcREanxWCQ9WuE6HXdhr6iKNx33308/fTT2O12lixZwqxZs8jPz28vc/fdd7f/edWqVZSUlADQ2NjII488wssvv4xOp2PRokXMmjWL+Pj4XmiK6HFKCHPFRixH/4O57B30gUZUUzTBEZfhH3UVoezpYOj6Qao3GObDY428X+Zia5mLupYgeh1MyIzj1pkjmFWQIm+/CtEPug394uJicnNzycnJAWDhwoWsX7++Q+h/3urVq7nlllsA2LJlCxdddBEJCW1vSV500UVs3ryZyy+/vKfqL3qBzteAreQfWPc+i8Fb29ajz51NYMR8grmzwNh5PRpV0zhU18IHJ8bmP30DNtps4PzcRC4akcSMEUkkyotRQvSrbkPf4XCQnp7e/rPdbqe4uLjLstXV1VRVVTFt2rSTnutwOM62zqKXGOv3Yit+Csuhf6NTgwRzLqZl5gMEh13SZY9e0zR2VXlYvc/B1nI3Tm/bOvSj02L45rnZXJCXyMTMOIwGWeZAiIGi29DXNK3TsZMtLbt69Wrmz5+PwWD40ud+ymDQkZAQ1V21TnG+/qzOHyx6rJ0hH7r9r6P/5Fn0ldvQTNGok76Jet4N6FJGEwV88S7+kMJ/9tbyzAfHKKlpIs5qZEZ+CjMLUpkxKqXH34CVv9OhJ1LaOhDb2W3op6enU1tb2/6zw+EgLS2ty7Jr1qxhxYoVHc7dsWNHh3OnTp16yvspikZjo6/bip9MQkLUWZ0/WJxtOw0NJdj2rsJy+N/og80ocbm0XPgL/GOvQ7OceObyuetrmkbx8SZWlzh452A9LQGFEclR3DN3FJcWpn02dz6s9Pj3L3+nQ0+ktLUv25maGnta5boN/fHjx1NeXk5lZSV2u53Vq1fz0EMPdSp39OhRmpqamDx5cvux6dOn88c//hGPp213oi1btnDbbbedbhtET9M0zEfXELX7r5hqdqAZLATyL8dfeB2hzGmd3ogFaPKHWFNSxyvFNZQ5fViNemYVpHD5ODvn5iTIhiJCDDLdhr7RaGTFihUsW7YMRVFYvHgxo0aNYuXKlRQVFTF79mygbWhnwYIFHUIgISGBG2+8kSVLlgBw0003tT/UFX3L4DxAzOZfYK7+4LNefeE1J31pyhdU+NuHlfxjZxX+sMrY9Fh+Pm8Uc0anEm2W1zuEGKx0WlcD7/0oFDq74QH5tbEjg7sUW/FTWPc9h2aOxTvtLvxjvw76rpcyCKsab+6t5bGtx3B6g8wdncrS83IYbe96Dn5fkL/ToSdS2jooh3fEIKRpmCreJWr3k5gr30PTm/CP/TreaXeetGcfVlTWlNTx1PYKqj1+JmTG8eBVYynKiOvjygshepOE/hBjOr6d6G2/w1SzAyXajvf8/6Z17DfQolK7LN/YGuKNvbW89MlxjjcFKLTHcNsl45gxIknG64UYgiT0hwhjXTFR2/+ApWIjSpSd5pkP4C+8Dgxdvwx13OPnqW0VvHWgjkBYZUp2PHfMHsWFwxMl7IUYwiT0BzmD6zDR23+H5ehbqJYEWi64m9bx/wWmzm/NArh8QZ7aVsHLu2vQ6+DycelcPTmT/JToPq65EKI/SOgPVsEWorc+gG33k2hGG96pt9M6cRmaueuHOZqm8cY+B396t5TWoMIVReksuyAXe6xsJShEJJHQH2xUBcvhf2Pc/ltMzTW0Fl6L94K70WzJJz2lrjnAA+8c5v0yF5Oz4rh7bgF5yQPrLUEhRN+Q0B8sNA1z2Vqit/8Bo+sgmn0C7nmPEU4/56SnHKxr4Z+7qll7oA6dTsdtl4zk2smZ6GXMXoiIJaE/COi9tcRuuB1zxXuEE0bQNO8v2M69mrCn692kdld7eGzrMXZWNGI16rmiKJ1vnptNdkLX4/xCiMghoT/AmY+8Sey7d6JTAjTPuA9/0bdBb8TWxa5UBxzNPLq5nG3H3CRFmfjRxcO5anw6cVbZPFwI0UZCf6AKtRKz+efY9v+TUNpEmuf8GSVxZJdFfUGFx7eW88KuauKsbWF/9aRM2UBcCNGJhP4AZHCXErf2+xidB/Ce8yN85/3kpDtUbS938+u3D1HbHGDxxAxunjGcGIv8tQohuibpMJBoGpZDLxPz3j1gMNN4+SpCuZd0WVRRNR57v5yntlWQlxTFk9dNZGKWbEMphDg1Cf0BQhfwEPPe3VgPv0YoYypNcx9Bjc3ssmxDS4Afv7qPrUedXDHOzh2z82UoRwhxWiT0BwBj7UfErf0hel8d3vPvxDflxi5XwfQFFZ7bWclzO6tQNfjFvAKuHJ/exRWFEH1N0zQqvceo9laTH19AqrXjeleKphBSQwSVIAHFT0u4BW/Yi9VgIS9mBEZ938SxhH4/s+57jphNv0CNyaBx0b8J2yd1WW7dwXr+sOEILl+I2QUp3LWgkASDzLcXoic0h5rY1bCTsBomwZJIgjmRdFsG0abOy5NomoY76KLKW0m1t4pKbwXHWsopadyLJ9jYXi7dlsHIhBE4vPXUtTpoCnlOen+T3szI2HyWDL+WWZlze6WNn5LQ7y9KkJhN92AreZ7gsJk0zX2ky2WP/SGFh987ysu7axibHsuDV41jfGZcxKxHLiKb099AsesTUm12hseMINoUTVgN0+Cvxx10A523AwmpIXxhL96QF4PeQGZUNtnR2Rh1JhoCbQHs9DfgDrpxBZzsc+9hn3sPKmqnayWaE8mMzsaoMxJU23roNb4aWpXP/tsz6oxkRmUxLfVCxidNJCs6myOeQ+xxF+PwHyfZkkxh/FgSLUlYDBbMejMWg4VoYwzRphhaQs0c8hzkkOcAzoCzN79OQDZR6R9hP3Frf4ClfB3ec27BN/WnXQ7nVDW2csfrJRyu9/Lt87L54UV5GA1t8/MHRTt7SKS0NVLaCadua1AJsv7426w//jafOHd1COM4UzzNoSa0LsL+TBh0BobHjmRa2oVMTb2AOFMc7qALd8BNja+aam8Vx33VaGiY9CbMejN2WzpZ0Tlkn/jHbrVjOMnQjGyiIiDoJX7NdzFVb6V55m/xF32zy2Iltc3c+speVE3j4UVFXDQ8qY8rKsSXp2karYoPd8CNO+hGj45ESxKJliQ0TcN7Yhy7RtXh9DQRVkMkWZLIiMpCj463q9/ib4f/Sp3fQVZUNtfnL2Va2kW4Ay7Km49S21pDkiWZNJudRHMS+i5eUjToDESbYog2tv1WUOWrpNpbSUgNkWazk2a1k2xNIdGcRKwpttNS4sPI7auvq19I6PchXauT+DXfw+jYRfOcPxEYvaTLctvKXdzxegkJNhN/XjyevCRZHE30rpAa4qDnAK1hHyE1hIZKvCmBBEtie3gG1SA1vuPsqP+A7fUfUO+vIzMqi6yoHIx6I9XeKqp9lXjD3i99fz16ok3RNIeaGR1fyE/H/4xzUs7rEMgX2qefUdtGxHX9UmOkktDvI8b6vcT9Zxl6Xz1N8/6XYP7lXZZ7fU8tD6w7zIjkKFYuKiI1RpY+Fj3L6W+gOdRMSA3iDrrZVLuRzbXv0hxqPq3zTXozk5Imc17qNI77qilvOUpYDZMVnU1h4qXYbekkmZNIsCSiairugIvGoBsduvYeeHJcPMFWDYPOQEOgnmpvFXWtDi60z2C6/WLZyKcXSej3AcuhfxO78aeo1kQaF71COG1ipzJhVePhd0v558fHmTosgd9dOVberBVfWm1rDU5/AyE1REgNYtZbiDZFY9SZ2FH/ARuOr+NQ04EO59gMUVxkn8GM9K+QaE7EbDADOjzBRtxBF96QF5PeiFlvId6cwISkSdiMZ7d4XyQ9vxhoJFV6mbXkBWI3/pRgxvk0XfpYl3vVNvvD3PVGCTsqGvn6lCx+NHMERr30dET3NE3jaPMRtjg2sbn2PY42Hzll+dHxY1g+5ibsVjsmvQmbMYpxieOxGqx9VGPR3yT0e5Hl8BvEvHsHwZyZeBY+BYbOQzWNrSFueWkPRxq8/GJ+AVcWyctWojNVU3EFnO1TDd0BFyWNe9le/wEN/np06ChKnMAPC39EbkweJr0Jk85EUA3SEm7BH25lbGIR2dE5/d0U0c8k9HuJuXwdsetuIZR+Hp7Lnuwy8J3eIDe9VEylu5UHrxrHRSNkhk4kU1SFPa7dbHG8x+GmQwSVICE1RHOoiQZ/PWEt3KF8lDGKc1Omcn7qhZyfdiFJFvn3R3RPQr8XmCo3EffW9wmnjKPp8me63KS8wRvkB//cjaM5wJ++VsTU3M4vZonBK6AEOOQ5QFZ0Tpdh3Bxq4mhzKceay6nyVlDlq+Jw0wGcficmvYlRcaOxGWzEmePJjckl1WonzWYn5cRUwwRLImlWe5+9ui+GDvk3poeZqj8gfs13URJG4LniuS43Km/2h/nRy3uoawnwP4vHMylbVscc7LwhL9W+Ssqaj/JB3RZ21G/Dr7TtbJYVlc2o+NH4FT/ugIsGfz3OQEP7uRa9hazobM6zn8e5iRdwfuqFXb7+L0RPkNDvQcaancS/uRQlNofGq17oclmF1pDCra/upczp4+GvFUngD0JBJUhp8xH2ufew172bfe69HUI8yZLMvKzLOCdlKsd91ex17+agZz/RxhgSzYnkxQwnN3Y4w2NGMDx2BCnWVPQ6vcxoEX1CQr+H6JsqiV+9FCU6Dc9VL6DZkjuVaQ0p3Pl6CXtrmnjg8kLOz5MhncGirPkoayrfoNj1CWXNpe3j63ZbOpOSpzAidiRZ0TnkROeQGzO8w5ui1/KN/qq2EJ1I6PcEJUDc2h+ApuG54jnUaHunIlWNrfz3ayWUNni5e+4oZhd0nropBgZVU6n311HlraSi5Rjv1qxnj3s3Jr2J8YkTuXr41ymIH83YhCJSbWn9XV0hvhQJ/R4Qs/mXmOp247nsr6jxeZ0+f/+oi1+sOYBOBw8vKuJCWUdnwNA0jeO+ag569nPQc4BDngMcbjqIL/zZMEtmVBbLx9zEpVkLSLDIb2dicJPQP0uWgy9j27cK3+QfEhwxv9Pn28pd3P7vvYxMieZ3V44lO+Hs3mQUZ0fVVMqaS9nl/IiPG3ay172HlnDb8gMmvZn8uFHMzbqMkSeGa7KjckixpsqyAGLIkNA/CwZ3KbHv3kUw83y80+7s9HmZ08ddb+xnREo0T1w3kWizfN29rTnUhCvgojHgPrEEb5vGoJuPnR/xifMjGk9sdJEdPYyZGZcwOr6QMQmFfbp7kRD9Rf4NP1NhP3Frf4hmtNE871H4Qlg0+kL85NW9WIx6/vjVcRL4PcgdcLHb9TEmvZkkSxIGnZEd9R+wpXZTp3VlPi/ZksJ5qdOYknwuU5LPlfF4EZEkic5QzNZfY3SW4Fn4N9TojksnBMIqd7xRQn1LgMeumUh6nKxrcra8IS9rq9ewqXYje13FXe5yNDahiO8VfJ/0qIz2tdI/nUVjNdjIjMqSYRoR8U4r9Ddt2sT999+PqqpcffXVLF++vFOZNWvW8Mgjj6DT6RgzZgwPPfQQAIWFhRQUFACQkZHBY4891oPV7x/mo2ux7XkG38QbCObN7vCZomqsWHOAj6s83L9wDOMz4/qplkODK+Bi1SdP8uKhF/GGWxgeM4Jv5n+HaWkXotfpcQVctIZ9FCVN7LQRtRCis25DX1EU7rvvPp5++mnsdjtLlixh1qxZ5Ofnt5cpLy/niSee4Pnnnyc+Ph6n87N9Hq1WK6+99lrv1L4f6L0OYjf+lFDqeLwX3NXhM03T+MOGI2w43MBPvjKCeWNk+OBMHWk6xMtlL7Kh5h3CapgZ6TO5dsQ3KUwY299VE2JQ6zb0i4uLyc3NJSenbXW+hQsXsn79+g6h/+KLL3L99dcTH9/2dmlycucWrBl0AAAgAElEQVQXk4YETSNmw0/RhXw0z/2fTouo/XVbBS/vruHb5+XwjXOy+6mSg5cn6GFT7UbWVa9lj3s3VoOVy7Iv578mfId4VXrxQvSEbkPf4XCQnv7ZmLXdbqe4uLhDmfLycgCuu+46VFXl5ptv5uKLLwYgEAiwaNEijEYjy5cvZ86cOae8n8GgIyHhzLcHNBj0Z3X+qeh3PYOhYiPKvN8SO3xCh8+2HGng8a3H+OrETH5+xdheHzvuzXb2JV/Ix7tVG3nr2Ftsq/mAsBYmLy6PH0+6la/lLyLOHIfBoEdROo/hDzVD5e/0dERKWwdiO7sNfU3rvOv8FwNNURSOHTvGqlWrqK2t5frrr+fNN98kLi6OjRs3YrfbqaysZOnSpRQUFDBs2LCT3k9RtLNaf6S31i/RN5aR9M49BLNn4Mn/BnzuHm5fkJ++VMzw5Chunzkcj6e1x+//RYN1nRZN06j0HmNXw0fscu7kw/ptBNQAqdY0FuVdw+zMueTHFaDT6VB90OjzDdq2flmR0k6InLb2ZTtTUzsv7tiVbkM/PT2d2tra9p8dDgdpaR3Hqu12O5MmTcJkMpGTk8Pw4cMpLy9nwoQJ2O1tSxLk5OQwdepUSkpKThn6A5KqELf+J2gGM82zH4LPrauiaRr3rT1Esz/E/ywuwmoy9GNF+1+tr4YNNe+w4fg6qrwVpFrTSLPZMeqM1PnrqGt10Kq0/Udgt6UzP3sBszLnUpQ4ocN6NUKI3tFt6I8fP57y8nIqKyux2+2sXr26fWbOp+bMmcPq1atZtGgRLpeL8vJycnJy8Hg82Gw2zGYzLpeLXbt2sWzZsl5rTG+xffIEptqdNM1ZiRqT2eGzFz8+zpajLn56yUhGpcb0Uw17ji/s5a2qNdT6jtMYdNMUaibGGEOiJQmrwUqlt4Ky5lJqW2sx6AyY9SYMOgPBE3uyBtUg0DZ98sphX8MZaKDOX4dP9ZITPYxzUs4jLyaPycnnyhRKIfpBt6FvNBpZsWIFy5YtQ1EUFi9ezKhRo1i5ciVFRUXMnj2bGTNm8P7777NgwQIMBgN33HEHiYmJ7Nq1i3vvvRedToemadxwww0dHgAPBgbXIaJ3PEhg+HwCBYs6fFbhbuV/NpcxfUQS10zOPMkVBgdVU1lXvZb/O/gXnIEGrAYbieZEYkyxVHkraAy6aQ23khmVRV7sCC5Im46GSlANoaoKJoMJs95MgjmRGelfISNqcH8fQgxVOq2rQft+FAopA2dMXw2T8PJVGJoqcH19Q4dNzVVN4wcvFnO4voUXv3MuqTGdt0PsTT3VTl/Yy3s1G3m94hUOeg4wJn4sN4+9lbGJRZ3KqpraL0MwMv479ERKWwflmH4ks33yeNvqmfMf6xD4AC/vruHjKg+/mFfQ54F/phRNYV31Wsqaj+INt9AYbOSjhg/xK61kRw/jzgk/Z27WpScNdhlzF2Lwk9A/CV2wmahd/0sgdzbB/Ms7fFbT5OeRTWWcn5vAFUWd184fiPY3lvCnvb/nSNMhTHozMcYYok0xzMqcw6XZlzMuoUjG14WIABL6J2ErfgZ9wINv6m0djmuaxu/WHUFD4+65BQM2KANKoH2N+H3uYjbXvkeSJZkVk3/NzPRLBmy9hRC9S0K/C7pgC7ZPHieQO4tw2sQOn713xMn7ZS5unTmCzPiBuZDaroad/K7419T76wBItaaxZPh1fDv/u7LhthARTkK/C9a9f0MfaMR37q0djvtDCg9tLGVkShTXDsDZOkElwJMHH+Ol8n+SHT2MX035DeMSi0iyDNFlMYQQX5qE/heFfER9/DjBYTMJp0/p8NFT2yuobQ7wxIKJGA0D46FmS6iFrY7NbKvfys76HbSEm7kqdzHfH3MTVsPA/E1ECNF/JPS/wLbv7+j9LrzndRzLP+byserDKhaMTWNydnw/1e4zmqbxXs0G/rzvj7iDLpIsycxIn8ncrEuZlDyl+wsIISKShP7naSq2Pc8QyphKOP2czw5rGg9uKMVi1HPLxSP6p2qahsNfizvgxh1w8c7uNbxX/S6j4kbzqykPMDaxSKZUCiG6JaH/OaaqLRiajuE9/6cdjq8/1MC2Y25uv2QkKdHmPq2To7WWt6v/w9qqNRz3Vbcftxqs/GDMzSzOuwaD7OsqhDhNkhafY9v7LKo1icDIBe3HvMEwf3q3lILUaJZM6ruHt6VNR1h15Gk2176LhsakpClcPfw60qzpJFgSKczIh9a+/T8gIcTgJ6F/gr6lBnPZO7ROWt5hc5T/21pBXUuQ31wxFqO+9+e217U6eLRkJZsd7xJljOLrI7/FwpwrO61lk2CJorF16L/GLoToWRL6J1hL/gGaSuu4b7YfO9Lg5YVdVVxVlM6EPtjrdo9rN7/cdTd+JcC387/L4uHXEGuSPXaFED1HQh9ACWEt+QehYTNR43PbDz+yqYxoi5GbZwzv1dtrmsbqytf5876HSLdl8Mdpj5Ibk9er9xRCRCYJfcB8bB0Gr4OWmb9pP3awroX3y1z84KJcEqJMvXbvI02HeHz/o3zk/JDzUs7n55N/Jb17IUSvkdAHbHufQ4nJIJg7q/3YM9sriDYbuGZSVo/fzxvystv1Me/WrGf98beJNcVyU+GP+WreEgy6yN55SwjRuyI+9PWecsyV7+GdejucmPpY7vKx/lADS6fmEGvtma9I1VTed2zmpbIX2Ne4F1VTsOgtXDPiG1w/8tvEmE5vLWwhhDgbER/6tpJ/oOkM+Auvaz/2tx2VmI16vn5Oz/Ty33ds4ulDT3K0+QhZUdl8Y+S3mJJ8LmMTijAbZNqlEKLvRHboKwGs+/9JMG8OakwG0LZW/n/217FkYgZJUWcfyP848ixPHnqM7Ohh/GziCmZlzJGXqYQQ/Sai08dy9C30rU5ai77VfuyFXdXogG+em31W19Y0jacP/x/PHXmG2ZnzuHPCzzFK2Ash+llEp5B133MoccMI5VwMQEhRWVNSx8z8ZNLjznyFypZQC3899DivHXuZBTlX8JOiO+QBrRBiQIjY0De4j2Cu/oCWaXfBiYXKNh910dga4oqi9DO6ZkuomZfLX+TlshdpCTezOO9aflh4iyyEJoQYMCI29K0HXjrxAPfa9mNv7K0lLcbMtNzEL329pmAT33//Ozhaa7nIfjHfyv8vCuJH92SVhRDirEVm6GsaliOvE8qejhaVCkB9S4CtZS6WTs3B8CXX2NE0jT/suR+nv4GHp/0vE5Im9UathRDirEXkuIOxbjeGpgr8o65sP/bmPgeqBleM+/JDO68de4X3HZtZPuYmCXwhxIAWkaFvOfw6mt5EcMSlQFtP/Y29tUzOjicn0falrlXadJi/HPgfpqVeyOK8a3qjukII0WMiL/Q1FcuR1wkOuwTN0rbt4SfVTVQ2+rmyyP6lLhVUAvz6k3uJM8Vxx4R70Ol6f+llIYQ4GxEX+qaaDzF4awl8bmjntT01RJsNzC5I/VLXeurQ/3GspZw7JtxDguXLP/wVQoi+FnGhbzn8OprRSiBvLgDN/jDrDjUwf0waNtPpz6Xf6yrmX2XPc0XOVzkv9fzeqq4QQvSoyAp9NYyl9M22wDdHA/DWgToCYZWrxp/+A9zWcCu/K/41dls63y+8qbdqK4QQPS6ipmyajm9H3+okkH9F+7HX9tRSkBpNoT3mtK6haRr/u38l1b4q/nj+I0QZo3urukII0eMiqqdvqt6KpjO0L7uw39HMwboWvjoh47Qfwj516HFWV77OdSO+yaTkKb1ZXSGE6HGRFfrHtxFOLUIzt/XqX9tTi8Wo59Ixaad1/t+P/I2/lz7LwpwruWH0D3uzqkII0SsiJ/SVACbHJ4Qy2h66toYU3tpfx5yClG43SgmrYZ459CR/PfQ4czLnc2vRf8v0TCHEoHRaob9p0ybmz5/P3LlzeeKJJ7oss2bNGhYsWMDChQu5/fbb24+/+uqrzJs3j3nz5vHqq6/2TK3PgNGxG50SIJTZFvobDjXgDSpcNT7jlOcdbNzPD9//Hs8eeYq5WZdy54R7ZMVMIcSg1e2DXEVRuO+++3j66aex2+0sWbKEWbNmkZ+f316mvLycJ554gueff574+HicTicAjY2NPPLII7z88svodDoWLVrErFmziI+P770WnYT5+HYAQplTAVh3qJ70WAuTsk6+Cfk/Sp/lqYNPkGhJ4r4pv2F6+sw+qasQQvSWbnv6xcXF5ObmkpOTg9lsZuHChaxfv75DmRdffJHrr7++PcyTk5MB2LJlCxdddBEJCQnEx8dz0UUXsXnz5l5oRvdMNdsJJ41GsybS7A+zrdzN7ILULodpNE3jmUNP8uTBx5iZMYunL/6HBL4QYkjoNvQdDgfp6Z/NYbfb7Tgcjg5lysvLKSsr47rrruOaa65h06ZNp31un1DDGGt2Espo6+VvKnUSVjXmjE7pVPTTHa+ePfIUl2Yv5O5J9xJjOr3pnEIIMdB1O7yjaVqnY1/sHSuKwrFjx1i1ahW1tbVcf/31vPnmm6d17hcZDDoSEqK6q9Ypztd3Pr/mE/ShFkyjLiYhIYr3ylxkxlu5aIy9U32eP/gPnjvyDF8b+TXumfqLAbsBSpftHKIipa2R0k6InLYOxHZ2G/rp6enU1ta2/+xwOEhL6zjF0W63M2nSJEwmEzk5OQwfPpzy8nLS09PZsWNHh3OnTp16yvspikZjo+/LtqNdQkJUp/NthzZhAjzxE/HUNrH5cAPXTM7E42ntUM4dcPG/ux9lauo0biq4nSaP/4zr0du6audQFSltjZR2QuS0tS/bmZoae1rluu3Gjh8/nvLyciorKwkGg6xevZpZs2Z1KDNnzhy2b297UOpyuSgvLycnJ4fp06ezZcsWPB4PHo+HLVu2MH369DNoztkxHd+GEjcMNSazfWhn7ujOi6v97fBf8St+biz80YDt4QshxNnotqdvNBpZsWIFy5YtQ1EUFi9ezKhRo1i5ciVFRUXMnj2bGTNm8P7777NgwQIMBgN33HEHiYltq07eeOONLFmyBICbbrqJhISE3m3RF2kapuM7CObNBj6btTMuveP/K5Y1H+XNite4KncRw2Ly+raOQgjRR3RaVwPv/SgUUnp0eMfgOkzS85fQfMkfaBh5NfP+8gFXT8rkJ18Z2eG8uz68jRL3PlZ95UXizX0/pfTLipRfjyFy2hop7YTIaeugHN4Z7IzOEgBCaRP5oNxNSNGYNarjrJ2d9TvYUb+Nb+V/Z1AEvhBCnKkhH/oG1yE0nR4lcSQfVTYSbTYwLqPjC1mvVbxCkiWZr+Yt6adaCiFE3xjyoW90HUSJzwODhV1VHiZkxmHUfzZN0xP0sL1uK7Mz52LSm/qvokII0QeGfOgbXIdRkgpw+4KUOX1Mye44fPNuzTrCWph5WZf1Uw2FEKLvDO3QVwIYPOWEk0bzcZUHgCk5HWcPvV39FiNi8xkZN6o/aiiEEH1qSIe+wV2KTlNQEkexq8qDxajvsENWRcsx9jfuY17Wpf1YSyGE6DtDOvSN7sMAhJMK2sfzTYbPmvxO9Vvo0TM7c15/VVEIIfrUkA79T2fuuG3DOFLv7TCer2oq646v5ZyU80i2dl54TQghhqIhHfqfztz5uCaABkzJ+Sz0d7s+xtFaKw9whRARZUiH/qczd3ZVNWI26BiX/tn8/BdKnyPenMBF6Rf3Yw2FEKJvDd3Q/8LMnXEZcViMbc3d597Dhw3buXb4N7AarP1cUSGE6DtDNvQ/nbnjjR3JwbqWDuP5zx5+inhzAlflLurHGgohRN8bsqH/6cyd/UomqgaTs9pCv8S9t72XbzMOrM0NhBCitw3Z0G+buWOguLVtw5eCtGgAnj0ivXwhROQasqH/6cydg64QSVEmEqPMHPIcZEf9NunlCyEi1pAN/baZO6MobfCSn9LWy9/q2IwePQuHXdnPtRNCiP4xNEP/xMydUGIBR50+8lPbQn+Xcyej4kcTa4rr5gJCCDE0DcnQNzRVotMU6szDCIRVRqZE4wt72d+4j3NSzuvv6gkhRL8ZkqGvb3UCUBFo6+GPSo2m2PUJiqYwJfnc/qyaEEL0qyEZ+jq/G4AjLWb0OhieFMVHDTsx680UJY7v59oJIUT/GZKhrz8R+vubTGQn2LCaDOxq+JDxiRMxGyz9XDshhOg/QzL0P+3p73EbyE+JxhVwUtZylCkpMrQjhIhsQzL09X43mt7MYQ/kp0Szq2EngDzEFUJEPGN/V6A36AKNBM3xaD4dI1Oj+bDhQ+JMcbIlohD9SFHCuN31hMNBHA4dmqb1d5V6XW+002g0k5iYisFwZvE9JENf73fj1bfNxc9PjuKJyo+YlDwFg87QzzUTInK53fVYrVFER6djNBpQFLW/q9TrDAZ9j7ZT0zS83ibc7npSUjLO6BpDcnhH53fTSCxWox7M9dT5HUxJlqEdIfpTOBwkOjoOnU7X31UZtHQ6HdHRcYTDwTO+xpAMfb2/kTolihEp0RxoLAFgfNKEfq6VEEIC/+yd7Xc4JENf53dzPGAjPyWKQ00HsBqsDIvJ6+9qCSFEvxt6Y/qaht7vxhGOYmRKNNs8BxkZN0rG84UQXHzxVEaMyEdRwuTmDufnP/8VVqu1w/GMjCx+8Yv7iI2NPeW1/vnPv/P444/y+utvExMTA8CaNW9w4EAJt912Z3u5m29ezs0338qYMWPx+Xw88sif2LlzB2azhfj4eG688ceMG1fUq+3+vKHX0w+2oFNDuLUYMuPNHGk6REHc6P6ulRBiALBYLDzzzD9YtepFTCYT//73S52Ox8XF8corL3Z7rXXr1jJmzFg2bdp42vf/3e/+H3Fx8bzwwqs899yL3H33vXg8jWfcnjMx9Hr6rW0vZrmJJax34Ff8jI4v7OdKCSE+7829tfy7uKZHr3llUToLx9lPu/zEiZM4cuRIp+NFReO7PP551dVVtLa2cuONP2bVqqdZsOCKbu9XXV1FSck+Vqz4NXp9W387KyubrKzs065zTxh6Pf1WFwCNWgwupQyAUfHS0xdCfCYcDrNt21ZGjszvcFxRFHbu/JDp0y8+5fnvvPMWc+bMZ+LEyVRUHMPtdnV7z7KyUvLzCzAY+neoecj19HUnQt+txXDcf+TEQ9zcfq6VEOLzLi9K57LCtD6/byAQ4Dvf+QbQ1tO//PKrOhyvrT3O6NGFnHfe+ae8zvr1b/PAAw+i1+uZOfMSNmxYx+LF15xiZs3AmbU05EL/0+GdgCmeoy275CGuEKLdp2P3Jzve0tLCHXfcyiuv/Iurr76uy2scOXKYqqpKfvKTmwAIhUJkZmaxePE1xMXF09zc3KF8c3MTCQkJxMbGcuTIYVRVbR/e6Q+ndedNmzYxf/585s6dyxNPPNHp81deeYVp06Zx1VVXcdVVV/Gvf/2r/bPCwsL24z/4wQ96ruYnofO19fQ1WzxHmg4xOn5Mr99TCDE0xMTEcOutP+X551cRDoe7LLNu3Vq++93lvPTSG7z00hu89tpbNDTUU1tbQ2HhWPbs2Y3T2QDA/v0lBINB0tLsZGVlM2ZMIX/96+PtSzNUVlawefO7fdU84DR6+oqicN999/H0009jt9tZsmQJs2bNIj+/41jYggULWLFiRafzrVYrr732Ws/VuDsnVtjUYsL4FT8FcRL6QojTV1Awhvz8AtatW8ully7s9Pn69W/z4IN/7nDs4ou/wrp1a/nmN7/Dj398O//93z9GVTWioqL45S8faO/Z33XXz3nkkYe59tqvYrVaiYuL56abftwn7fpUt6FfXFxMbm4uOTk5ACxcuJD169d3Cv0Bo9VFC1Hoo9pmBshDXCHEp955Z/NpHf/97/900mv861+vdzp2yy23tf95xoyvMGPGV4DOa+9ER8dw550//zJV7nHdhr7D4SA9Pb39Z7vdTnFxcadyb7/9Nh9++CHDhw/nZz/7GRkZbYsBBQIBFi1ahNFoZPny5cyZM+eU9zMYdCQkRH3ZdrTT+xtpJAZsx7GqViZkFWLQD70xfYNBf1bf02ASKW0d6u10OHQYDJ+NKH/+z0NZb7RTpzvznOw29LtaFvSLT6gvueQSLr/8csxmM88//zx33nknzz77LAAbN27EbrdTWVnJ0qVLKSgoYNiwYSe9n6JoNDb6vmw72iV5nTjVGFrUMvLjCmhuCpzxtQayhISos/qeBpNIaetQb6emae293p5efbI3lJYe4f/9v45D1iaTif/7v7+d9jV6q52a1jknU1NP/Qbxp7oN/fT0dGpra9t/djgcpKV1nGqVmJjY/udrrrmGBx98sP1nu73tZYmcnBymTp1KSUnJKUP/bCleJy4tmkb1GBfHX9lr9xFCDG0jR+Z3OdNnsOv2947x48dTXl5OZWUlwWCQ1atXM2vWrA5l6urq2v+8YcMGRo4cCYDH4yEYbFsC1OVysWvXrl5/FqD5XJSarIS1APlxBb16LyGEGGy67ekbjUZWrFjBsmXLUBSFxYsXM2rUKFauXElRURGzZ89m1apVbNiwAYPBQHx8PL/5zW8AKC0t5d5770Wna9s95oYbbuj10Nf73VQZ2n6TyLBl9uq9hBBisNFpA2zPslBIOfNxTTVM6l/yuNE2k83pZaya+SJZ0X27rkVfGerjv58XKW0d6u2srT1Genrb2/GDYUy/J/RWOz//XX7qdMf0h9Tjc52/bbU654nfX1Ksqf1YGyGEGHiG1DIM+hMvZjUZNWJNcVgMln6ukRBiIDnVuvlHj5by8MN/OPGMUuPSSxeydOn32mcrfvDB+zz55GP4/a1omsaFF87g5ptvPeX9vvWta8nNHc6vfvVA+7HPr68PUFNznDvuuJVVq9qWcy4p2cujj67E5XKi0+mYMGESt97631it1h75DoZU6OtOhH6rOUyqte8XcxJCDGyfX3vn17++l1deeZGlS79HIODnrrtu46c//RlTp07D7/dzzz138Mor/2Lx4ms4evQIf/rT7/nDH1aSm5tHOBzm9ddfPeW9ysvLUFWN3bs/prW1FZvN1m39XC4nv/jFXfzqVw9QVDQBTdN49931+HxeCf2u6ANtwzsBU5AUa04/10YIcTLm/f/CvO/5Hr2mv/A6AmOWnHb5z6+b/847bzF+/ESmTp0GtC0fc9ttd3DLLd9n8eJr+Pvfn+Xb3/4uubl5QNsEl0WLrj7l9d955y0uu2wBZWVlbNnyHnPnXtptnV555V9cdtnlFBW17emt0+m45JJTv9D6ZQ2xMf22nn7Q4CPFmtLPtRFCDFRfXDe/rOwoo0d33GwpKysbn8+H19tCWVlpp8+7s379O8yePY85c+azbt3a0zrn6NFSRo/u3fXChlZP3+8mBAT1LTK8I8QAFiy8mtaCxX1+35Otm69p2knXwj/5Gvknt3//PhITE8jIyCQ5OZXf/OY+mpqaiIuL6/J6Z3KPMzW0evqtbo4bzIDM3BFCdPbpmP5LL71JKBTilVfaloEfPnwkBw6UdChbXV1FVFQUUVHRDB8+goMH95/2fdatW8uxY8f42tcWcu21X8Xr9fLeexsAiI+Pp7m5qb1sU1MT8fEJJ+oxgoMHD5xtM09pSIV+2OvkqKFtV3rp6QshTuaL6+bPm3cpxcW7+fDD7QAEAn5WrnyQb3zjWwB8/evfZtWqp6moOAaAqqq88MJzXV5bVVU2blzP3/72PK++upqXXnqD3/72ofYhnsmTz2Ht2v+0r2v2n/+8yZQp5wKwePE1/Oc/b7Jv3972661du6Z9ff6eMKSGdxSfi3JD28pzKRbp6QshTu6L6+b/9rcP8ac//Z4//vF3qKrK/PkLWLz4WgDy80fxox/dzi9/eQ+BgB+dTscFF0zv8rqffLKLlJRUUlM/63hOnDiZ8vKjNDQ0cOWVizh2rJzvfOfrgI4xYwr5wQ9uBiApKZlf/eoBHn30YdxuF3q9nokTJzNz5qwu73UmhtQbuYYXvsqjQTcvpoT495y3iDPH9XDtBo6h/vbm50VKW4d6O+WN3J5zNm/kDqmevt7fSK3JiFmvJ9Z0el+AEEJEkiEV+qZgIw22VJIsSX36NFwIEZn+9re/snHj+g7HLrlkNkuXfq+fatS9oRP6moYl7MFtTCXNJg9xhRC9b+nS7w3ogO/K0Jm9E/Jh1EI0mxTSZLqmEEJ0aeiEvsnGZtssvIaQzNEXQoiTGDqhr9PzgG0Zmk6R0BdCiJMYOqEPuAL1AKTIi1lCCNGlIRX6TWEnAKnS0xdC9JNwONzfVTilITN7pzWkENZ5MCJv4wohuvazn92Ow+EgGAxy9dXXcdVVi9i2bStPPPEoiqKSkJDAypV/wefz8fDDf+DAgRJ0Oh3/9V838JWvzGbu3Bm8885mADZuXMfWrVu4555fcv/9vyQuLo5Dhw5SUDCG2bPn8uc//5FAIIDFYuHuu1cwbFgeiqLwl7/8Dzt2fIBOp+OKK75KXt4IXn75RX7zmwcB+PDDbbz66ss88MAfeuU7GDKhbzXqmThM43BIT5Ilqb+rI4Q4hbcq17Cm4o0eveZl2ZczL/uyU5b52c9WEBcXTyDgZ9mybzNjxkx+//v7eeSRJ8jMzKKpyQPAM888SXR0DM8++0+gbVG07lRWVvDww/+LwWDA623hkUeewGIxs23bBzz++KPcf/8feP31V6mpqeapp/6O0WikqclDbGwcf/zj73C73SQmJrJ69RssWHDF2X8hJzFkQl+n0zHcHsLlTMagHzLNEkL0oH/96wU2bXoXgLo6B6+//ioTJ04mMzMLgLi4eAB27tzRYYvDuLjul3S55JI5GAwGgP/f3r3FRJnecRz/opNZ2CIix9FK7AKlYRExm7pIoxeiDOfNeGqWWJdDGg+JTBCDEdlsLAqmGyTRpKmy1CoXJjYSMQFUVlCHRDwQUFvlhjVsBhcGV5HZQY7D9IIyLqtII+DgO//P3bwzzPt/5k9+8+Z54XmwWCwcOnSAxz1WjjoAAAd9SURBVI+NwMspn8bGW+h0G1GpVOPOFxubQE1NNQkJn/Hgwb/58su/THmsE1FUOj7p78L/Q39HlyGEmERcQAIxiybfSWo6NTU10th4mxMn/omrqyu7dm0jOPi39pUzx5toff2XxwYHB8c98/PtDEtLj/PJJ7/n66+LaW9vJzNz++i72sa/x5jExM/Yu3c3avUHrFmz1v6lMBMUdSP3x/4f8ZX/xhVCvEZvr4V58zxwdXXl++/bePjwPwwODnH3bhM//PAYwD69s2LFSsrL/2X/2bHpHS8vr//tfTuCwXB1wnNZLBZ8fUfvLVZXv5zG+vTTSC5cKLdf+Y+dz8fHFx8fX06f/gfx8TM3tQOKC/0n+H0ooS+EeFVk5B+wWq2kpn7ON9/8nY8/Xoqnpyc5OfvJy8shNTWFr77KBUaXV/jpJzNbt/6R1NQUmpsbAdixYxd792ah1+/A23viLVm3bPmC48f/xrZt6YyMvFxlMylJh7+/hrS0FFJTU/j220v257TaOPz8/Pnoo8AZ+gRGKWZp5X5rPwmXo8mM0LP+15/PQGWzi9KX4f05Zxmr0scpSyu/WXHxXwkJ+R1JSbpJXzuVpZUVc6X/wZwP+CI4g7jfvPnuvRBCzDYZGX/iu+9a0WoTZvxcirmR6+LiQlrIn/H8lbKvloQQynPy5Ou3XpwJirnSF0IIMTkJfSHEOzPLbiG+l6b6GUroCyHeCZVKTW+vWYJ/Cmw2G729ZlQq9Vu/h2Lm9IUQs9uCBb50dz/BYnmOi4uLU4T/TIxTpVKzYMHbry8moS+EeCfmzlXh47MQUP6fp46ZjeOU6R0hhHAiEvpCCOFEJPSFEMKJzLplGIQQQswcudIXQggnIqEvhBBOREJfCCGciIS+EEI4EQl9IYRwIhL6QgjhRBQT+gaDgdjYWGJiYigpKXF0OdOqo6ODrVu3Eh8fT2JiIqdPnwbg+fPnpKeno9VqSU9Pp6enx8GVTg+r1YpOp2P79tHNpI1GI5s3b0ar1ZKVlfXKhtTvK7PZjF6vJy4ujvj4eJqbmxXZ01OnTpGYmEhSUhLZ2dkMDAwopqe5ublERUWRlJRkPzZRD202G4cOHSImJobk5GQePHjgkJoVEfpWq5X8/HxKS0upqqqisrKS1tZWR5c1bebOncu+ffu4ePEiZ8+e5cyZM7S2tlJSUkJUVBQ1NTVERUUp5suurKyMoKAg++OioiLS0tKoqanBw8ODc+fOObC66VNQUMDq1au5dOkSFy5cICgoSHE9NZlMlJWVUV5eTmVlJVarlaqqKsX0dMOGDZSWlo47NlEPDQYDbW1t1NTUcPDgQQ4cOOCAihUS+vfv32fJkiUEBASgVqtJTEyktrbW0WVNGz8/P8LCwgBwd3cnMDAQk8lEbW0tOt3ofpo6nY4rV644ssxp0dnZybVr19i0aRMwenV08+ZNYmNjAVi/fr0iemuxWLhz5459nGq1Gg8PD0X21Gq10t/fz/DwMP39/fj6+iqmpytWrGD+/Pnjjk3Uw7HjLi4uLF++HLPZTFdX1zuvWRGhbzKZ0Gg09sf+/v6YTCYHVjRz2tvbaWlpISIigqdPn+Ln5weMfjE8e/bMwdVNXWFhITk5OcyZM/qr2d3djYeHByrV6IKwGo1GEb01Go14eXmRm5uLTqcjLy+PFy9eKK6n/v7+ZGRksGbNGlatWoW7uzthYWGK7OmYiXr4y5xy1LgVEfqvW0nCxcXFAZXMrN7eXvR6Pfv378fd3d3R5Uy7q1ev4uXlxdKlS9/4OiX0dnh4mIcPH5KSkkJFRQVubm7v/VTO6/T09FBbW0ttbS319fX09fVhMBheeZ0SejqZ2ZJTilhPX6PR0NnZaX9sMpns37RKMTQ0hF6vJzk5Ga1WC4C3tzddXV34+fnR1dWFl5eXg6ucmqamJurq6jAYDAwMDGCxWCgoKMBsNjM8PIxKpaKzs1MRvdVoNGg0GiIiIgCIi4ujpKREcT29ceMGixcvto9Dq9XS3NysyJ6OmaiHv8wpR41bEVf64eHhtLW1YTQaGRwcpKqqiujoaEeXNW1sNht5eXkEBgaSnp5uPx4dHU1FRQUAFRUVrF271lElTos9e/ZgMBioq6ujuLiYlStXcuTIESIjI7l8+TIA58+fV0RvfX190Wg0PHr0CICGhgaCgoIU19NFixZx7949+vr6sNlsNDQ0EBwcrMiejpmoh2PHbTYbd+/eZd68eQ4JfcWssnn9+nUKCwuxWq1s3LiRnTt3OrqkadPY2MiWLVsICQmxz3VnZ2ezbNkysrKy6OjoYOHChRw9ehRPT08HVzs9bt26xcmTJzlx4gRGo5Hdu3fT09NDaGgoRUVFqNVvv0fobNHS0kJeXh5DQ0MEBARw+PBhRkZGFNfTY8eOUV1djUqlIjQ0lIKCAkwmkyJ6mp2dze3bt+nu7sbb25vMzEzWrVv32h7abDby8/Opr6/Hzc2NwsJCwsPD33nNigl9IYQQk1PE9I4QQoj/j4S+EEI4EQl9IYRwIhL6QgjhRCT0hRDCiUjoCyGEE5HQF0IIJyKhL4QQTuS/FUYUySX6zfAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scm.metrics['validation'].drop('loss', axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f867ebc34a8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scm.metrics['training']['loss'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `scoreMetrics` method to calculate a variety of goodness-of-fit metrics on a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.746555</td>\n",
       "      <td>0.743861</td>\n",
       "      <td>0.6762</td>\n",
       "      <td>0.693101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PR_AUC   ROC_AUC  accuracy      loss\n",
       "0  0.746555  0.743861    0.6762  0.693101"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scm.scoreMetrics(D_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `entropy` method calculates the conditional entropy of the cadre-assignment random variable. This quantifies the confidence of an observation's most likely cadre-assignment.\n",
    "\n",
    "Each cadre (value of `M`) gets its own conditional entropy. Conditional entropies close to `log2(M)` indicate lots of uncertainty in cadre-assignment for that cadre, and conditional entropies close to 0 indicate very little uncertainty.\n",
    "\n",
    "More detail about the use of conditional entropy can be found in `arXiv:1808.04880`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.321928094887362"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These conditional entropies are all fairly close to their maximum value. This means that the SCM's classification function should not be treated as being very piecewise linear -- there is a lot of nonlinearity in predicted labels. We could try to fix this by retraining with a larger `gamma` value, or we can simply accept it.\n",
    "\n",
    "This particular dataset is fairly nonlinear, I believe, so it's not surprising that the conditional entropies are large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.08914561, 3.09106624, 3.19445972, 3.09472192, 3.10619275,\n",
       "       3.01084184, 3.05615803, 3.18887349, 3.10599752, 3.0484128 ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scm.entropy(D_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predictFull` method is the one-step prediction function for a new dataset. It returns:\n",
    "\n",
    "- `f` -- classification margins\n",
    "- `l` -- predicted labels\n",
    "- `G` -- cadre-membership probabilities\n",
    "- `m` -- predicted cadres\n",
    "- `l` -- loss function value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, l, G, m, l = scm.predictFull(D_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    1380\n",
       "9    1259\n",
       "6    1243\n",
       "1    1243\n",
       "4    1075\n",
       "3    1012\n",
       "8     921\n",
       "0     801\n",
       "7     584\n",
       "2     482\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(m).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the `predictFull` method, there are more specific prediction methods:\n",
    "- `predictMargin` -- returns `f`\n",
    "- `predictClass` -- returns `l`\n",
    "- `predictCadre` -- returns `m`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to use 5-fold cross-validation for better hyperparameter tuning. This involves a lot of training, so we're going to do it in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scmCrossval(d_tr, d_va, d_te, M, l_W, l_d, cadre_fts, predict_fts, Tmax, record):\n",
    "    mod = binaryCadreModel(\n",
    "                Tmax=Tmax, record=record,\n",
    "                M=M, alpha_d=0.99, alpha_W=0.99, lambda_d=l_d, lambda_W=l_W, gamma=1.)\n",
    "        \n",
    "    mod.fit(d_tr, 'target', cadre_fts, predict_fts, d_va, progress=False)\n",
    "    \n",
    "    ## evaluate on validation and test sets\n",
    "    err_va = mod.scoreMetrics(d_va)\n",
    "    err_te = mod.scoreMetrics(d_te)\n",
    "    \n",
    "    ## return everything as a list\n",
    "    return mod, err_va, err_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the possible hyperparameter configurations we are going to search over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_ds = np.array([0.01, 0.001])\n",
    "l_Ws = np.array([0.01, 0.001])\n",
    "Ms = np.array([4,6,8,10])\n",
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=12)]: Done   2 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=12)]: Done   3 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=12)]: Done   4 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=12)]: Done   5 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=12)]: Done   6 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=12)]: Done   7 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=12)]: Done   9 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=12)]: Done  10 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=12)]: Done  11 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=12)]: Done  12 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=12)]: Done  13 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=12)]: Done  14 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=12)]: Done  15 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=12)]: Done  16 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=12)]: Done  18 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=12)]: Done  19 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=12)]: Done  20 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=12)]: Done  21 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=12)]: Done  22 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=12)]: Done  23 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=12)]: Done  24 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=12)]: Done  25 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=12)]: Done  28 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=12)]: Done  29 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=12)]: Done  30 tasks      | elapsed: 22.7min\n",
      "[Parallel(n_jobs=12)]: Done  31 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=12)]: Done  32 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=12)]: Done  33 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=12)]: Done  34 tasks      | elapsed: 29.8min\n",
      "[Parallel(n_jobs=12)]: Done  35 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=12)]: Done  36 tasks      | elapsed: 30.8min\n",
      "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=12)]: Done  38 tasks      | elapsed: 31.5min\n",
      "[Parallel(n_jobs=12)]: Done  39 tasks      | elapsed: 31.5min\n",
      "[Parallel(n_jobs=12)]: Done  40 tasks      | elapsed: 32.8min\n",
      "[Parallel(n_jobs=12)]: Done  41 tasks      | elapsed: 33.4min\n",
      "[Parallel(n_jobs=12)]: Done  42 tasks      | elapsed: 33.4min\n",
      "[Parallel(n_jobs=12)]: Done  43 tasks      | elapsed: 34.6min\n",
      "[Parallel(n_jobs=12)]: Done  44 tasks      | elapsed: 35.5min\n",
      "[Parallel(n_jobs=12)]: Done  45 tasks      | elapsed: 36.1min\n",
      "[Parallel(n_jobs=12)]: Done  46 tasks      | elapsed: 36.4min\n",
      "[Parallel(n_jobs=12)]: Done  47 tasks      | elapsed: 36.5min\n",
      "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed: 36.8min\n",
      "[Parallel(n_jobs=12)]: Done  49 tasks      | elapsed: 36.9min\n",
      "[Parallel(n_jobs=12)]: Done  50 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=12)]: Done  51 tasks      | elapsed: 38.3min\n",
      "[Parallel(n_jobs=12)]: Done  52 tasks      | elapsed: 43.2min\n",
      "[Parallel(n_jobs=12)]: Done  53 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=12)]: Done  54 tasks      | elapsed: 44.5min\n",
      "[Parallel(n_jobs=12)]: Done  55 tasks      | elapsed: 45.0min\n",
      "[Parallel(n_jobs=12)]: Done  56 tasks      | elapsed: 46.2min\n",
      "[Parallel(n_jobs=12)]: Done  57 tasks      | elapsed: 46.4min\n",
      "[Parallel(n_jobs=12)]: Done  65 out of  80 | elapsed: 49.3min remaining: 11.4min\n",
      "[Parallel(n_jobs=12)]: Done  73 out of  80 | elapsed: 53.4min remaining:  5.1min\n",
      "[Parallel(n_jobs=12)]: Done  80 out of  80 | elapsed: 62.7min finished\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=n_folds, random_state=1414)\n",
    "\n",
    "n_jobs = np.minimum(12, n_folds * Ms.shape[0] * l_ds.shape[0] * l_Ws.shape[0])\n",
    "\n",
    "results = (Parallel(n_jobs=n_jobs, backend='threading', verbose=11)(delayed(scmCrossval)\n",
    "                    (D_tr.iloc[tr], D_tr.iloc[va], D_va, M, l_W, l_d, features, features, 20001, 1000) \n",
    "                    for (M, l_d, l_W, (fold, (tr, va))) in product(Ms, l_ds, l_Ws, enumerate(kf.split(D_tr)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function lets us organize the cross-validation accuracy of each hyperparameter configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scores(results):\n",
    "    results_va, results_te = [], []\n",
    "    for model, scores_va, scores_te in results:\n",
    "        results_va.append(scores_va)\n",
    "        results_va[-1] = results_va[-1].assign(M=model.M, lambda_d=model.lambda_d, lambda_W=model.lambda_W)\n",
    "        \n",
    "        results_te.append(scores_te)\n",
    "        results_te[-1] = results_te[-1].assign(M=model.M, lambda_d=model.lambda_d, lambda_W=model.lambda_W)\n",
    "    results_va = pd.concat(results_va).reset_index(drop=True)\n",
    "    results_te = pd.concat(results_te).reset_index(drop=True)\n",
    "    print(results_va.head())\n",
    "    print(results_te.head())\n",
    "    return results_va, results_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PR_AUC   ROC_AUC  accuracy      loss  M  lambda_d  lambda_W\n",
      "0  0.604021  0.602929  0.551625  0.840378  4      0.01      0.01\n",
      "1  0.613960  0.622548  0.584375  0.816942  4      0.01      0.01\n",
      "2  0.642983  0.647375  0.604875  0.757063  4      0.01      0.01\n",
      "3  0.618331  0.630848  0.599500  0.833157  4      0.01      0.01\n",
      "4  0.674285  0.662441  0.618750  0.741088  4      0.01      0.01\n",
      "     PR_AUC   ROC_AUC  accuracy      loss  M  lambda_d  lambda_W\n",
      "0  0.602458  0.598755    0.5457  0.840810  4      0.01      0.01\n",
      "1  0.622536  0.622885    0.5847  0.816972  4      0.01      0.01\n",
      "2  0.661772  0.661841    0.6108  0.756728  4      0.01      0.01\n",
      "3  0.622284  0.629413    0.5864  0.832929  4      0.01      0.01\n",
      "4  0.660926  0.645047    0.6035  0.741301  4      0.01      0.01\n"
     ]
    }
   ],
   "source": [
    "scores_va, scores_te = extract_scores(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function decides which hyperparameter configuration has the best validation accuracy on average, as measured by `ROC_AUC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_attributes(scores):\n",
    "    group = scores.groupby(['M','lambda_d','lambda_W'])\n",
    "    return group.mean().reset_index().sort_values('ROC_AUC', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>lambda_d</th>\n",
       "      <th>lambda_W</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.784182</td>\n",
       "      <td>0.785212</td>\n",
       "      <td>0.711075</td>\n",
       "      <td>0.657471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.768799</td>\n",
       "      <td>0.773369</td>\n",
       "      <td>0.701000</td>\n",
       "      <td>0.672957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.770133</td>\n",
       "      <td>0.772715</td>\n",
       "      <td>0.701675</td>\n",
       "      <td>0.649345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.749394</td>\n",
       "      <td>0.752592</td>\n",
       "      <td>0.681225</td>\n",
       "      <td>0.684820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.735939</td>\n",
       "      <td>0.735982</td>\n",
       "      <td>0.672900</td>\n",
       "      <td>0.765081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     M  lambda_d  lambda_W    PR_AUC   ROC_AUC  accuracy      loss\n",
       "4    6     0.001     0.001  0.784182  0.785212  0.711075  0.657471\n",
       "8    8     0.001     0.001  0.768799  0.773369  0.701000  0.672957\n",
       "0    4     0.001     0.001  0.770133  0.772715  0.701675  0.649345\n",
       "12  10     0.001     0.001  0.749394  0.752592  0.681225  0.684820\n",
       "6    6     0.010     0.001  0.735939  0.735982  0.672900  0.765081"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_attributes(scores_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll train a final model on the entire training dataset with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers being printed: SGD iteration, training loss, training accuracy, validation loss, validation accuracy, time\n",
      "0\n",
      "1000 1.387868 0.5104 1.3802397 0.5102 0.1609952449798584\n",
      "2000 1.0543379 0.630375 1.0541757 0.6275 30.08755588531494\n",
      "3000 1.0130858 0.66165 1.0136889 0.6566 60.266019105911255\n",
      "4000 0.9949055 0.67395 0.9959138 0.6682 91.91009736061096\n",
      "5000 0.9844632 0.68165 0.9856071 0.6769 123.66660165786743\n",
      "6000 0.97760457 0.687175 0.97879696 0.6824 157.73456501960754\n",
      "7000 0.9728447 0.691 0.9740023 0.6861 188.15894436836243\n",
      "8000 0.9690816 0.694275 0.9702438 0.6888 219.48974514007568\n",
      "9000 0.9660039 0.6967 0.967153 0.6922 250.92584085464478\n",
      "10000 0.96339166 0.6987 0.96453387 0.6954 282.02784395217896\n",
      "11000 0.961117 0.7006 0.9622772 0.6964 314.2528963088989\n",
      "12000 0.9590633 0.7022 0.9602563 0.698 346.16024470329285\n",
      "13000 0.9573027 0.703075 0.9585674 0.7004 378.1253855228424\n",
      "14000 0.95571285 0.7046 0.9570452 0.7019 411.07925605773926\n",
      "15000 0.95418906 0.706775 0.9556563 0.7035 442.9778628349304\n",
      "16000 0.95273405 0.707725 0.95427394 0.7045 472.7344973087311\n",
      "17000 0.95142037 0.709575 0.95307064 0.7055 503.95069694519043\n",
      "18000 0.9501459 0.7117 0.951857 0.7073 536.3612205982208\n",
      "19000 0.9489216 0.7123 0.95073915 0.7083 568.5978302955627\n",
      "20000 0.9477365 0.71345 0.94964594 0.7099 599.4213716983795\n",
      "training has terminated because: model took 20001 SGD steps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<classificationBinary.binaryCadreModel at 0x7f861470b400>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scm_best = binaryCadreModel(Tmax=20001, record=1000, eps=1e-4, lambda_W=0.001, lambda_d=0.001, M=6, gamma=1.)\n",
    "scm_best.fit(D_tr, 'target', features, features, D_va, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the accuracy of the original untuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.746555</td>\n",
       "      <td>0.743861</td>\n",
       "      <td>0.6762</td>\n",
       "      <td>0.693101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PR_AUC   ROC_AUC  accuracy      loss\n",
       "0  0.746555  0.743861    0.6762  0.693101"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scm.scoreMetrics(D_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the accuracy of the tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788421</td>\n",
       "      <td>0.787379</td>\n",
       "      <td>0.7102</td>\n",
       "      <td>0.657289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PR_AUC   ROC_AUC  accuracy      loss\n",
       "0  0.788421  0.787379    0.7102  0.657289"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scm_best.scoreMetrics(D_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, by utilizing proper hyperparameter tuning, we are able to increase our `PR_AUC` and `ROC_AUC` scores by about 5% and our accuracy by about 4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function can be used to calculate subpopulation-specific metrics. It can be useful to notice if one subpopulation has particularly good or bad accuracy relative to the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_metrics(data, model, data_name, M):\n",
    "    F, L, __, M, __ = model.predictFull(data)\n",
    "    temp = pd.DataFrame({'f': np.squeeze(F), 'm': np.squeeze(M), 'l': np.squeeze(L), 'y': data['target'].values})\n",
    "    scores = {'size': [], 'm': [], 'dataset': [], 'accuracy': [], 'ROC_AUC': [], 'PR_AUC': [], 'proportion': []}\n",
    "    for m in np.unique(M):\n",
    "        temp_m = temp.loc[temp['m']==m,:]\n",
    "        if temp_m.shape[0] < 5: continue\n",
    "        scores['size'].append(temp_m.shape[0])\n",
    "        scores['m'].append(m)\n",
    "        scores['dataset'].append(data_name)\n",
    "        scores['proportion'].append(temp_m['y'].mean())\n",
    "        scores['accuracy'].append(np.mean(temp_m['l'] == temp_m['y']))\n",
    "        scores['ROC_AUC'].append(roc_auc_score(temp_m['y'], temp_m['f']))\n",
    "        scores['PR_AUC'].append(average_precision_score(temp_m['y'], temp_m['f']))\n",
    "    return pd.DataFrame(scores)[['dataset', 'm', 'size', 'proportion', 'accuracy', 'ROC_AUC', 'PR_AUC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>m</th>\n",
       "      <th>size</th>\n",
       "      <th>proportion</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>PR_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synthetic</td>\n",
       "      <td>0</td>\n",
       "      <td>1404</td>\n",
       "      <td>0.505698</td>\n",
       "      <td>0.724359</td>\n",
       "      <td>0.793205</td>\n",
       "      <td>0.796738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>synthetic</td>\n",
       "      <td>1</td>\n",
       "      <td>1666</td>\n",
       "      <td>0.597239</td>\n",
       "      <td>0.717287</td>\n",
       "      <td>0.779810</td>\n",
       "      <td>0.837128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>synthetic</td>\n",
       "      <td>2</td>\n",
       "      <td>2516</td>\n",
       "      <td>0.411367</td>\n",
       "      <td>0.717011</td>\n",
       "      <td>0.791501</td>\n",
       "      <td>0.717528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>synthetic</td>\n",
       "      <td>3</td>\n",
       "      <td>1414</td>\n",
       "      <td>0.389675</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.731547</td>\n",
       "      <td>0.615325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synthetic</td>\n",
       "      <td>4</td>\n",
       "      <td>1492</td>\n",
       "      <td>0.615282</td>\n",
       "      <td>0.715818</td>\n",
       "      <td>0.789958</td>\n",
       "      <td>0.857002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>synthetic</td>\n",
       "      <td>5</td>\n",
       "      <td>1508</td>\n",
       "      <td>0.548408</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.780402</td>\n",
       "      <td>0.806799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset  m  size  proportion  accuracy   ROC_AUC    PR_AUC\n",
       "0  synthetic  0  1404    0.505698  0.724359  0.793205  0.796738\n",
       "1  synthetic  1  1666    0.597239  0.717287  0.779810  0.837128\n",
       "2  synthetic  2  2516    0.411367  0.717011  0.791501  0.717528\n",
       "3  synthetic  3  1414    0.389675  0.673267  0.731547  0.615325\n",
       "4  synthetic  4  1492    0.615282  0.715818  0.789958  0.857002\n",
       "5  synthetic  5  1508    0.548408  0.706897  0.780402  0.806799"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_metrics(D_va, scm_best, 'synthetic', 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we see that cadre 4 has the best `PR_AUC`, and cadre 0 has the best `ROC_AUC`. Cadre 3 has the worst `ROC_AUC` and `PR_AUC`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_root]",
   "language": "python",
   "name": "conda-env-my_root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
