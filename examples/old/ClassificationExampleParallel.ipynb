{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the goal is to perform parallelized model selection and then report final test set accuracy.\n",
    "\n",
    "Structure of notebook:\n",
    "\n",
    "* Load data\n",
    "* Perform train-test split\n",
    "* Define dictionary of hyperparameters\n",
    "* Do cross-validation to select best hyperparameters\n",
    "* Train final model\n",
    "* Evaluate final model on test set, using bootstrapping to obtain confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load base packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "from scipy.stats import zscore, zmap\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command lets you edit `.py` files and have the changed versions be accessed by Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load cadre modeling package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../cadreModels/')\n",
    "from classificationBinary import binaryCadreModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `breastcancer` and then extract observations, labels, and features. Note that we're turning the labels into a rank-2 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breastcancer = load_breast_cancer()\n",
    "X, Y, features = breastcancer['data'], np.expand_dims(breastcancer['target'], 1), breastcancer['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map `Y` values to -1 and +1 for hinge loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = 2 * Y - 1\n",
    "pd.DataFrame(Y)[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a randomized train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xte, Ytr, Yte = train_test_split(X, Y, test_size=0.2, random_state=1515)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary of hyperparameters used for model selection. We're holding the sparsity parameters `alpha_d` and `alpha_W` fixed at their default values of 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scm_params = {'M': np.array([2,3]), 'lambda_d': np.array([0.01, 0.1]), 'lambda_W': np.array([0.01, 0.1])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-fold cross-validation index generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, random_state=1414)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments to the SCM initialization function:\n",
    "\n",
    "* `M` -- number of cadres\n",
    "* `lambda_d` -- regularization strength hyperparameter for cadre-assignment weight `d`\n",
    "* `lambda_W` -- regularization strength hyperparameter for classification-weights `W`\n",
    "* `alpha_d` -- sparsity parameter for `d`\n",
    "* `alpha_W` -- sparsity parameter for `W`\n",
    "* `Tmax` -- number of total iterations\n",
    "* `record` -- how often during training to evaluate loss and accuracy\n",
    "* `gamma` -- cadre-assignment sharpness hyperparameter\n",
    "\n",
    "In this analysis, we're using a small `Tmax` value, but larger ones may be needed for more complex datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required arguments to SCM fit method:\n",
    "\n",
    "* `Xtr` -- training feature values, in `np.array` format\n",
    "* `Ytr` -- training labels, in `np.array` format\n",
    "\n",
    "Optional arguments to SCM fit method:\n",
    "\n",
    "* `Xva` -- validation feature values, in `np.array` format\n",
    "* `Yva` -- validation labels, in `np.array` format\n",
    "* `names` -- list or `pd.Index` of feature names\n",
    "* `seed` -- RNG seed for parameter initalization SGD\n",
    "* `store` -- whether or not to store copy of training data in SCM object, False by default\n",
    "* `progress` -- whether or not to print diagnostics during training, False by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $N$ is the number of observations, and $P$ is the number of features, `Xtr` and `Xva` should be $N \\times P$ arrays, and `Ytr` and `Yva` should be $N\\times1$ arrays. If the labels are supplied as rank-1 arrays instead of rank-2 arrays, TensorFlow will automatically do some broadcasting that won't reflect what you want it do be doing.\n",
    "\n",
    "The fit method doesn't automatically standardize data, so, if applicable, that should be performed prior to fitting\n",
    "\n",
    "If `progress=True`, the printed diagnostics will be:\n",
    "\n",
    "Iteration Number, Loss Value, Training Accuracy, Validation Accuracy (if applicable), Time\n",
    "\n",
    "You can supply `Xva` and `Yva` to monitor for overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`alpha_d` and `alpha_W` should be between 0 and 1; if they are close to 1, then the parameters `d` and `W` will be more likely to be sparse.\n",
    "\n",
    "The SCM optimization problem sometimes suffers from ill-conditioning. When this happens, it's best to change `gamma` or `lambda_d`. I've found that `gamma=10` works fairly well for datasets with tens of non-sparse features; as dimensionality increases, it may need to be decreased. Increasing `lambda_d` will also make estimated values of `d` smaller, which helps with conditioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'M': [], 'lambda_d': [], 'lambda_W': [], 'accuracy': [], 'loss': []}\n",
    "for M, l_d, l_W in product(scm_params['M'], scm_params['lambda_d'], scm_params['lambda_W']):\n",
    "    print(M, l_d, l_W)\n",
    "    for (tr, va) in kf.split(Xtr):\n",
    "        ## split training data into training and validation sets\n",
    "        x_tr, x_va, y_tr, y_va = Xtr[tr,:], Xtr[va,:], Ytr[tr,:], Ytr[va,:]\n",
    "        ## standardize validation data with respect to training data and then standardize training data\n",
    "        x_va = zmap(x_va, x_tr)\n",
    "        x_tr = zscore(x_tr)\n",
    "        ## initalize and fit SCM model object with current hyperparameters\n",
    "        scm_mod = binaryCadreModel(M=M, lambda_d=l_d, lambda_W=l_W, Tmax=201, record=10, gamma=5.)\n",
    "        scm_mod.fit(Xtr=x_tr, Ytr=y_tr, Xva=x_va, Yva=y_va, names=features, progress=False)\n",
    "        ## update records\n",
    "        scores['M'].append(M)\n",
    "        scores['lambda_d'].append(l_d)\n",
    "        scores['lambda_W'].append(l_W)\n",
    "        scores['accuracy'].append(scm_mod.score(x_va, y_va))\n",
    "        scores['loss'].append(scm_mod.loss[-1])\n",
    "## transform scores in DataFrame for easy analysis\n",
    "scores = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify best hyperparameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = scores.groupby(['M','lambda_W','lambda_d']).mean().sort_values('accuracy', ascending=False)\n",
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate a model using all of the training data and the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_M = best_hyperparameters['M'].values[0]\n",
    "best_l_d = best_hyperparameters['lambda_d'].values[0]\n",
    "best_l_W = best_hyperparameters['lambda_W'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scm_best = binaryCadreModel(M=best_M, lambda_d=best_l_d, lambda_W=best_l_W, Tmax=201, record=10, gamma=5.)\n",
    "x_te = zmap(Xte, Xtr)\n",
    "x_tr = zscore(Xtr)\n",
    "scm_best.fit(Xtr=x_tr, Ytr=Ytr, Xva=x_te, Yva=Yte, names=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate convergence by plotting loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'loss': scm_best.loss,\n",
    "             'TrainingAccuracy': scm_best.accs,\n",
    "            'TestingAccuracy': scm_best.accsVa}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the values of the classification weight parameter `W`. `W` is a set of $M$ length-$P$ column vectors. The value of the $p$th component in the $m$th column quantifies the association between the predicted label and that feature. As the value becomes more positive, the feature becomes more positively associated with the `+1` label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at a plot like this, it's often informative to see what features are used similarly between cadres and which are used differently. In the plot below, for example, `texture error` is associated with class `+1` in `w1` (orange) and associated with class `-1` in `w0` (blue). Also, `worst radius` has a much stronger association with class `-1` in `w1` than it does with `w2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_df = pd.DataFrame(scm_best.W, columns=['w0','w1'], index=scm_best.columns).reset_index().assign(baseline=0)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 5)\n",
    "p = sns.lineplot(x='index', y='weight', hue='cadre', data=W_df.melt('index', var_name='cadre', value_name='weight'))\n",
    "for item in p.get_xticklabels():\n",
    "    item.set_rotation(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the distributions of features by cadre. First we predict each training point's label and cadre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__, l_tr, __, m_tr = scm_best.predictFull(x_tr)\n",
    "augmented_data = pd.DataFrame(x_tr, columns=scm_best.columns).assign(cadre=m_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print counts of every (cadre, true label, predicted label) combination. Cadre 0 primarily contains `+1` points, and cadre 1 primarily contains `-1` points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'true_y': Ytr[:,0], 'pred_y': l_tr[:,0], 'cadre': m_tr}).groupby(['cadre', 'true_y', 'pred_y']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We bind the features and cadre into a single `DataFrame` and find feature means, which we plot by cadre. They are very distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_means = augmented_data.groupby('cadre').mean().reset_index().melt(id_vars='cadre', var_name='feature', value_name='mean_value')\n",
    "sns.lineplot(x='feature', y='mean_value', hue='cadre', data=feature_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The breastcancer dataset is fairly small, and training is quick. But for larger datasets, training will take longer, and it is advantageous to perform model selection by training in parallel. The main package you need for this is `joblib`, which implements parallelized `for` loops. (The common term is \"embarassingly parallel\".) We've also loading `multiprocessing`, but we only use it to detect how many cores we have access to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we see how many cores we have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use some or all of these to speed up the process.\n",
    "\n",
    "Notes:\n",
    "\n",
    "* It's not always the best to use every core at once. Having to wait for each core's job to finish before moving on can produce delays. Also, TensorFlow will automatically parallelize some large matrix computations, I believe. So forcing each core to train a separate model can result in slower training times.\n",
    "* It looks like Jupyter has access to 16 cores. Node-03 on the server has 48, although you have to run that through the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine hyperparameters and cross-validation setting. In practice, you'd want to use 10 or 20 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scm_params = {'M': np.array([2,3]), 'lambda_d': np.array([0.01, 0.1]), 'lambda_W': np.array([0.01, 0.1])}\n",
    "kf = KFold(n_splits=3, random_state=1414)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a function that trains a single model and returns its validation set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scmCrossval(Xtr, Ytr, Xva, Yva, Tmax, M, a_W, l_W, a_d, l_d, gamma, features, fold):\n",
    "    ## standardize validation data with respect to training data and then standardize training data\n",
    "    x_va = zmap(Xva, Xtr)\n",
    "    x_tr = zscore(Xtr)\n",
    "    ## initalize and fit SCM model object with current hyperparameters\n",
    "    scm_mod = binaryCadreModel(M=M, alpha_d=a_d, alpha_W=a_W, lambda_d=l_d, lambda_W=l_W, Tmax=Tmax, record=10, gamma=gamma)\n",
    "    scm_mod.fit(Xtr=x_tr, Ytr=Ytr, names=features)\n",
    "    \n",
    "    ## extract final loss value\n",
    "    loss = scm_mod.loss[-1]\n",
    "    \n",
    "    ## calculate training set accuracy\n",
    "    tra_acc = scm_mod.score(x_tr, Ytr)\n",
    "    \n",
    "    ## calculate validation set accuracy\n",
    "    val_acc = scm_mod.score(x_va, Yva)\n",
    "    \n",
    "    ## return everything as a list\n",
    "    return fold, M, a_W, l_W, a_d, l_d, gamma, loss, tra_acc, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we invoke `joblib` to do the parallelized training. `joblib`'s `Parallel` function is the workhorse here. It's syntax is kind of verbose and confusing, unfortunately. First we describe the type of job we do, then we specify the function that is to be parallelized (wrapping it in `delayed`), and then we specify the parallelized functions arguments.\n",
    "\n",
    "The parallelization backend we use is `\"threading\"`, as opposed to the default of `\"multiprocessing\"`. My experience is that `\"threading\"` works better when each parallelized function call (i.e., `scmCrossVal` call) is fairly memory-intensive. Setting `verbose=11` ensures that you are notified each time a job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 8\n",
    "a_d = 0.9\n",
    "a_W = 0.9\n",
    "gamma = 5.\n",
    "Tmax = 201\n",
    "\n",
    "scores = (Parallel(n_jobs=8, backend='threading', verbose=11)(delayed(scmCrossval)\n",
    "          (Xtr[tr,:], Ytr[tr,:], Xtr[va,:], Ytr[va,:], Tmax, M, a_W, l_W, a_d, l_d, gamma, features, fold) \n",
    "                        for (M, l_d, l_W, (fold, (tr, va))) in product(scm_params['M'], scm_params['lambda_d'], scm_params['lambda_W'], enumerate(kf.split(Xtr)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Parallel` returns out cross-validation results as a list of tuples. So we need to reshape everything a `pd.DataFrame` for easier comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'fold': [], 'M': [], 'a_W': [], 'l_W': [], 'a_d': [], 'l_d': [], 'gamma': [], 'loss': [], 'training_acc': [], \n",
    "           'validation_acc': []}\n",
    "for fold, M, a_W, l_W, a_d, l_d, gamma, loss, tra_acc, val_acc in scores:\n",
    "    results['fold'].append(fold)\n",
    "    results['M'].append(M)\n",
    "    results['a_W'].append(a_W)\n",
    "    results['l_W'].append(l_W)\n",
    "    results['a_d'].append(a_d)\n",
    "    results['l_d'].append(l_d)\n",
    "    results['gamma'].append(gamma)\n",
    "    results['loss'].append(loss)\n",
    "    results['training_acc'].append(tra_acc)\n",
    "    results['validation_acc'].append(val_acc)\n",
    "results = pd.DataFrame(results)\n",
    "results.drop('fold', axis=1).groupby(['M','a_W','l_W','a_d','l_d','gamma']).mean().sort_values('validation_acc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can choose optimal hyperparameters as before and train a final model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_root]",
   "language": "python",
   "name": "conda-env-my_root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
